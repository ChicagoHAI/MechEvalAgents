{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9e2a0bf",
   "metadata": {},
   "source": [
    "# ICoT Code Questions - Solutions\n",
    "\n",
    "This notebook contains complete solutions for the three code-based assessment questions.\n",
    "\n",
    "**Important:** This notebook is for evaluation purposes. Students should only see the stubs in question_documentation.ipynb.\n",
    "\n",
    "Each code question includes:\n",
    "1. Student-facing stub (identical to question_documentation.ipynb)\n",
    "2. Complete solution with implementation\n",
    "3. Auto-check cell to validate results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b8b335",
   "metadata": {},
   "source": [
    "---\n",
    "## CQ1: Logit Attribution Pattern Verification\n",
    "\n",
    "**Objective:** Verify that input digit position aᵢ has strongest effect on output digit cₖ when i+j=k.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7d2bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CQ1: Logit Attribution Pattern Verification (STUB)\n",
    "import torch\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('/home/smallyan/critic_model_mechinterp/icot')\n",
    "from src.model_utils import load_hf_model\n",
    "from src.data_utils import prompt_ci_raw_format_batch\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# TODO: Load the ICoT model\n",
    "# TODO: Generate 100 random 4×4 multiplication problems\n",
    "# TODO: Compute logit attribution for each input-output pair\n",
    "# TODO: Print top-3 influential positions for each output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4a4c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CQ1: SOLUTION\n",
    "import torch\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('/home/smallyan/critic_model_mechinterp/icot')\n",
    "from src.model_utils import load_hf_model\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Load ICoT model\n",
    "config_path = \"/home/smallyan/critic_model_mechinterp/icot/ckpts/2L4H/config.json\"\n",
    "state_dict_path = \"/home/smallyan/critic_model_mechinterp/icot/ckpts/1_to_4_revops_2L_H4.pt\"\n",
    "\n",
    "print(\"Loading ICoT model...\")\n",
    "model, tokenizer = load_hf_model(config_path, state_dict_path)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Generate 100 random 4×4 multiplication problems\n",
    "n_samples = 100\n",
    "operands = []\n",
    "for _ in range(n_samples):\n",
    "    a = ''.join([str(np.random.randint(0, 10)) for _ in range(4)])\n",
    "    b = ''.join([str(np.random.randint(0, 10)) for _ in range(4)])\n",
    "    operands.append((a, b))\n",
    "\n",
    "print(f\"Generated {n_samples} random multiplication problems\")\n",
    "\n",
    "# Function to format input and get logits\n",
    "def get_output_logits(model, tokenizer, operand_pair, device):\n",
    "    a, b = operand_pair\n",
    "    # Format: \"a0a1a2a3 * b0b1b2b3%%%####\"\n",
    "    prompt = f\"{a} * {b}%%%####\"\n",
    "    tokens = tokenizer.encode(prompt, return_tensors='pt').to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(tokens)\n",
    "        logits = outputs.logits[0]  # Shape: [seq_len, vocab_size]\n",
    "    \n",
    "    # Return logits at positions where c0-c7 would be generated\n",
    "    # The output digits start after #### (4 # symbols)\n",
    "    sep_pos = len(tokenizer.encode(f\"{a} * {b}%%%####\")) - 1\n",
    "    return logits[sep_pos:sep_pos+8], tokens\n",
    "\n",
    "# Compute attribution for each input position on each output position\n",
    "print(\"Computing logit attribution...\")\n",
    "attribution_matrix = np.zeros((8, 8, n_samples))  # [input_pos, output_pos, sample]\n",
    "\n",
    "for sample_idx, (a, b) in enumerate(operands):\n",
    "    # Get baseline logits\n",
    "    baseline_logits, tokens = get_output_logits(model, tokenizer, (a, b), device)\n",
    "    \n",
    "    # For each input position (8 positions: 4 for a, 4 for b)\n",
    "    for input_pos in range(8):\n",
    "        # Create counterfactual by swapping digit\n",
    "        if input_pos < 4:  # Modify a\n",
    "            a_list = list(a)\n",
    "            original_digit = a_list[input_pos]\n",
    "            new_digit = str((int(original_digit) + 5) % 10)\n",
    "            a_list[input_pos] = new_digit\n",
    "            a_modified = ''.join(a_list)\n",
    "            counterfactual = (a_modified, b)\n",
    "        else:  # Modify b\n",
    "            b_list = list(b)\n",
    "            b_pos = input_pos - 4\n",
    "            original_digit = b_list[b_pos]\n",
    "            new_digit = str((int(original_digit) + 5) % 10)\n",
    "            b_list[b_pos] = new_digit\n",
    "            b_modified = ''.join(b_list)\n",
    "            counterfactual = (a, b_modified)\n",
    "        \n",
    "        # Get counterfactual logits\n",
    "        cf_logits, _ = get_output_logits(model, tokenizer, counterfactual, device)\n",
    "        \n",
    "        # Compute attribution as absolute difference in logits\n",
    "        # Focus on output positions c2-c6\n",
    "        for output_pos in range(2, 7):\n",
    "            if output_pos < len(baseline_logits) and output_pos < len(cf_logits):\n",
    "                # Get the logit for the correct digit\n",
    "                diff = torch.abs(baseline_logits[output_pos] - cf_logits[output_pos]).max().item()\n",
    "                attribution_matrix[input_pos, output_pos, sample_idx] = diff\n",
    "\n",
    "# Average across samples\n",
    "mean_attribution = attribution_matrix.mean(axis=2)\n",
    "\n",
    "# Identify top-3 positions for each output\n",
    "print(\"\\nTop-3 influential input positions for each output digit:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "results = {}\n",
    "for output_pos in range(2, 7):\n",
    "    scores = mean_attribution[:, output_pos]\n",
    "    top_3_idx = np.argsort(scores)[-3:][::-1]\n",
    "    \n",
    "    print(f\"\\nOutput c{output_pos}:\")\n",
    "    print(f\"  Expected pattern: positions where i+j={output_pos}\")\n",
    "    print(f\"  Top-3 positions: {top_3_idx.tolist()}\")\n",
    "    \n",
    "    # Check if top positions match i+j=k pattern\n",
    "    expected_positions = []\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            if i + j == output_pos:\n",
    "                # Position in input: a_i is at index i, b_j is at index j+4\n",
    "                expected_positions.extend([i, j+4])\n",
    "    expected_positions = list(set(expected_positions))[:6]  # Take first few\n",
    "    \n",
    "    print(f\"  Expected positions (i+j={output_pos}): {expected_positions}\")\n",
    "    \n",
    "    # Check overlap\n",
    "    overlap = len(set(top_3_idx.tolist()) & set(expected_positions))\n",
    "    print(f\"  Match quality: {overlap}/3 top positions match expected\")\n",
    "    \n",
    "    results[f\"c{output_pos}\"] = {\n",
    "        \"top_3\": top_3_idx.tolist(),\n",
    "        \"expected\": expected_positions,\n",
    "        \"overlap\": overlap\n",
    "    }\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"VERIFICATION COMPLETE\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cd0ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CQ1: AUTO-CHECK\n",
    "# Verify that the attribution pattern shows expected structure\n",
    "\n",
    "print(\"\\nAuto-check for CQ1:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Check that results were computed\n",
    "assert 'results' in locals(), \"Results not computed\"\n",
    "\n",
    "# Check that we have results for all output positions\n",
    "for k in range(2, 7):\n",
    "    assert f\"c{k}\" in results, f\"Missing results for c{k}\"\n",
    "\n",
    "# Check that most outputs show good matches (at least 2/3 positions match on average)\n",
    "total_overlap = sum(results[f\"c{k}\"][\"overlap\"] for k in range(2, 7))\n",
    "avg_overlap = total_overlap / 5\n",
    "\n",
    "print(f\"Average overlap with expected pattern: {avg_overlap:.1f}/3\")\n",
    "\n",
    "if avg_overlap >= 1.5:\n",
    "    print(\"✓ PASS: Attribution pattern shows i+j=k structure\")\n",
    "else:\n",
    "    print(\"✗ FAIL: Attribution pattern does not match expected structure\")\n",
    "\n",
    "print(f\"\\nExpected: Average overlap ≥ 1.5/3\")\n",
    "print(f\"Achieved: {avg_overlap:.1f}/3\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c28829",
   "metadata": {},
   "source": [
    "---\n",
    "## CQ2: Running Sum Linear Probe Accuracy\n",
    "\n",
    "**Objective:** Demonstrate that ĉₖ values are linearly decodable from ICoT hidden states.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad13555c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CQ2: Running Sum Linear Probe Accuracy (STUB)\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Ridge\n",
    "import sys\n",
    "sys.path.append('/home/smallyan/critic_model_mechinterp/icot')\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# TODO: Load ICoT model\n",
    "# TODO: Extract hidden states at layer 2 mid-point\n",
    "# TODO: Compute ground truth ĉₖ values\n",
    "# TODO: Train linear probes and evaluate MAE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c036491f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CQ2: SOLUTION\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import sys\n",
    "sys.path.append('/home/smallyan/critic_model_mechinterp/icot')\n",
    "from src.model_utils import load_hf_model\n",
    "from src.data_utils import read_operands\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Load ICoT model\n",
    "config_path = \"/home/smallyan/critic_model_mechinterp/icot/ckpts/2L4H/config.json\"\n",
    "state_dict_path = \"/home/smallyan/critic_model_mechinterp/icot/ckpts/1_to_4_revops_2L_H4.pt\"\n",
    "\n",
    "print(\"Loading ICoT model...\")\n",
    "model, tokenizer = load_hf_model(config_path, state_dict_path)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Load validation data\n",
    "data_path = \"/home/smallyan/critic_model_mechinterp/icot/data/processed_valid.txt\"\n",
    "all_operands = read_operands(data_path)[:300]  # Use 300 samples\n",
    "\n",
    "print(f\"Loaded {len(all_operands)} multiplication problems\")\n",
    "\n",
    "# Split into train and test\n",
    "train_operands = all_operands[:200]\n",
    "test_operands = all_operands[200:300]\n",
    "\n",
    "# Function to compute ground truth ĉₖ\n",
    "def compute_c_hat(a_str, b_str, k):\n",
    "    '''Compute the accumulated sum at position k'''\n",
    "    a_digits = [int(d) for d in a_str]\n",
    "    b_digits = [int(d) for d in b_str]\n",
    "    \n",
    "    # Compute sum of all products where i+j <= k\n",
    "    total = 0\n",
    "    for i in range(len(a_digits)):\n",
    "        for j in range(len(b_digits)):\n",
    "            if i + j <= k:\n",
    "                total += a_digits[i] * b_digits[j] * (10 ** (i + j))\n",
    "    \n",
    "    return total\n",
    "\n",
    "# Function to extract hidden states at layer 2 mid-point\n",
    "def extract_hidden_states(model, tokenizer, operand_pair, device):\n",
    "    a, b = operand_pair\n",
    "    prompt = f\"{a} * {b}%%%####\"\n",
    "    tokens = tokenizer.encode(prompt, return_tensors='pt').to(device)\n",
    "    \n",
    "    # Hook to capture layer 2 mid-point (after attention, before MLP)\n",
    "    hidden_states = {}\n",
    "    \n",
    "    def hook_fn(module, input, output):\n",
    "        # output is the hidden state after attention block\n",
    "        hidden_states['layer2_mid'] = output[0].detach()\n",
    "    \n",
    "    # Register hook on layer 1 (second layer, 0-indexed)\n",
    "    hook = model.transformer.h[1].register_forward_hook(hook_fn)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        _ = model(tokens)\n",
    "    \n",
    "    hook.remove()\n",
    "    \n",
    "    # Get states at output positions\n",
    "    # Output starts after #### \n",
    "    sep_pos = len(tokenizer.encode(f\"{a} * {b}%%%####\")) - 1\n",
    "    return hidden_states['layer2_mid'], sep_pos\n",
    "\n",
    "# Extract features and targets for k in {2, 3, 4}\n",
    "probe_results = {}\n",
    "\n",
    "for k in [2, 3, 4]:\n",
    "    print(f\"\\nProcessing k={k}...\")\n",
    "    \n",
    "    # Collect training data\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    \n",
    "    for a, b in train_operands:\n",
    "        hidden, sep_pos = extract_hidden_states(model, tokenizer, (a, b), device)\n",
    "        # Get hidden state at position where c_k is computed\n",
    "        if sep_pos + k < hidden.shape[1]:\n",
    "            h_k = hidden[0, sep_pos + k, :].cpu().numpy()\n",
    "            c_hat_k = compute_c_hat(a, b, k)\n",
    "            \n",
    "            X_train.append(h_k)\n",
    "            y_train.append(c_hat_k)\n",
    "    \n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train)\n",
    "    \n",
    "    print(f\"  Training samples: {len(X_train)}\")\n",
    "    \n",
    "    # Train linear probe with Ridge regression\n",
    "    probe = Ridge(alpha=0.01)\n",
    "    probe.fit(X_train, y_train)\n",
    "    \n",
    "    # Collect test data\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "    \n",
    "    for a, b in test_operands:\n",
    "        hidden, sep_pos = extract_hidden_states(model, tokenizer, (a, b), device)\n",
    "        if sep_pos + k < hidden.shape[1]:\n",
    "            h_k = hidden[0, sep_pos + k, :].cpu().numpy()\n",
    "            c_hat_k = compute_c_hat(a, b, k)\n",
    "            \n",
    "            X_test.append(h_k)\n",
    "            y_test.append(c_hat_k)\n",
    "    \n",
    "    X_test = np.array(X_test)\n",
    "    y_test = np.array(y_test)\n",
    "    \n",
    "    # Evaluate\n",
    "    y_pred = probe.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    \n",
    "    probe_results[k] = {\n",
    "        'mae': mae,\n",
    "        'n_train': len(X_train),\n",
    "        'n_test': len(X_test)\n",
    "    }\n",
    "    \n",
    "    print(f\"  Test samples: {len(X_test)}\")\n",
    "    print(f\"  MAE: {mae:.2f}\")\n",
    "\n",
    "# Print final results\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Mean Absolute Error for running sum prediction:\")\n",
    "print(\"=\" * 60)\n",
    "for k in [2, 3, 4]:\n",
    "    print(f\"ĉ_{k}: {probe_results[k]['mae']:.2f}\")\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2a0cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CQ2: AUTO-CHECK\n",
    "print(\"\\nAuto-check for CQ2:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Check that all MAE values are computed\n",
    "assert 'probe_results' in locals(), \"Probe results not computed\"\n",
    "\n",
    "for k in [2, 3, 4]:\n",
    "    assert k in probe_results, f\"Missing results for k={k}\"\n",
    "    mae = probe_results[k]['mae']\n",
    "    print(f\"ĉ_{k} MAE: {mae:.2f} (threshold: <5.0)\")\n",
    "    \n",
    "    if mae < 5.0:\n",
    "        print(f\"  ✓ PASS for k={k}\")\n",
    "    else:\n",
    "        print(f\"  ✗ FAIL for k={k}\")\n",
    "\n",
    "# Overall pass/fail\n",
    "all_pass = all(probe_results[k]['mae'] < 5.0 for k in [2, 3, 4])\n",
    "\n",
    "print(\"-\" * 40)\n",
    "if all_pass:\n",
    "    print(\"✓ ALL TESTS PASSED: Running sums are linearly decodable\")\n",
    "else:\n",
    "    print(\"✗ SOME TESTS FAILED: Check implementation\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7655e750",
   "metadata": {},
   "source": [
    "---\n",
    "## CQ3: Fourier Basis R² Computation for Digit Embeddings\n",
    "\n",
    "**Objective:** Verify that digit embeddings follow Fourier basis structure with k ∈ {0,1,2,5}.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8020353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CQ3: Fourier Basis R² Computation (STUB)\n",
    "import torch\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('/home/smallyan/critic_model_mechinterp/icot')\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# TODO: Load ICoT model and extract embeddings\n",
    "# TODO: Construct Fourier basis matrix\n",
    "# TODO: Fit coefficients and compute R² for each dimension\n",
    "# TODO: Report median R²\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8286da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CQ3: SOLUTION\n",
    "import torch\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('/home/smallyan/critic_model_mechinterp/icot')\n",
    "from src.model_utils import load_hf_model\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Load ICoT model\n",
    "config_path = \"/home/smallyan/critic_model_mechinterp/icot/ckpts/2L4H/config.json\"\n",
    "state_dict_path = \"/home/smallyan/critic_model_mechinterp/icot/ckpts/1_to_4_revops_2L_H4.pt\"\n",
    "\n",
    "print(\"Loading ICoT model...\")\n",
    "model, tokenizer = load_hf_model(config_path, state_dict_path)\n",
    "\n",
    "# Extract embedding matrix for digits 0-9\n",
    "# Token IDs for digits: tokenizer.encode('0')[0], etc.\n",
    "digit_token_ids = [tokenizer.encode(str(d))[0] for d in range(10)]\n",
    "print(f\"Digit token IDs: {digit_token_ids}\")\n",
    "\n",
    "embeddings = model.transformer.wte.weight[digit_token_ids, :].detach().cpu().numpy()\n",
    "print(f\"Embedding shape: {embeddings.shape}\")  # Should be (10, 768)\n",
    "\n",
    "# Construct Fourier basis matrix Φ (shape: 10 x 6)\n",
    "# Frequencies k ∈ {0, 1, 2, 5}\n",
    "# Basis: [constant, cos(2πn/10), sin(2πn/10), cos(2πn/5), sin(2πn/5), parity]\n",
    "\n",
    "n = np.arange(10)\n",
    "phi = np.column_stack([\n",
    "    np.ones(10),                      # k=0: constant\n",
    "    np.cos(2 * np.pi * n / 10),      # k=1: cos component\n",
    "    np.sin(2 * np.pi * n / 10),      # k=1: sin component\n",
    "    np.cos(2 * np.pi * n / 5),       # k=2: cos component (also k=2 mod 5)\n",
    "    np.sin(2 * np.pi * n / 5),       # k=2: sin component\n",
    "    (-1) ** n                         # k=5: parity (period 2)\n",
    "])\n",
    "\n",
    "print(f\"Fourier basis shape: {phi.shape}\")  # (10, 6)\n",
    "\n",
    "# For each embedding dimension, compute R²\n",
    "r2_values = []\n",
    "\n",
    "n_dims = embeddings.shape[1]\n",
    "for d in range(n_dims):\n",
    "    # Extract vector for this dimension across all digits\n",
    "    x_d = embeddings[:, d]  # Shape: (10,)\n",
    "    \n",
    "    # Fit coefficients using least squares: C_d = argmin ||x_d - Φ @ C||²\n",
    "    C_d, residuals, rank, s = np.linalg.lstsq(phi, x_d, rcond=None)\n",
    "    \n",
    "    # Compute predictions\n",
    "    x_pred = phi @ C_d\n",
    "    \n",
    "    # Compute R² = 1 - SS_res / SS_tot\n",
    "    ss_res = np.sum((x_d - x_pred) ** 2)\n",
    "    ss_tot = np.sum((x_d - np.mean(x_d)) ** 2)\n",
    "    \n",
    "    if ss_tot > 1e-10:  # Avoid division by zero\n",
    "        r2 = 1 - (ss_res / ss_tot)\n",
    "    else:\n",
    "        r2 = 0.0\n",
    "    \n",
    "    r2_values.append(r2)\n",
    "\n",
    "# Compute median R²\n",
    "r2_values = np.array(r2_values)\n",
    "median_r2 = np.median(r2_values)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Fourier Basis R² Analysis\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Number of embedding dimensions: {n_dims}\")\n",
    "print(f\"Median R²: {median_r2:.4f}\")\n",
    "print(f\"Mean R²: {np.mean(r2_values):.4f}\")\n",
    "print(f\"Std R²: {np.std(r2_values):.4f}\")\n",
    "print(f\"Min R²: {np.min(r2_values):.4f}\")\n",
    "print(f\"Max R²: {np.max(r2_values):.4f}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Show distribution\n",
    "percentiles = [25, 50, 75, 90, 95]\n",
    "print(\"\\nR² Distribution:\")\n",
    "for p in percentiles:\n",
    "    val = np.percentile(r2_values, p)\n",
    "    print(f\"  {p}th percentile: {val:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebcce4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CQ3: AUTO-CHECK\n",
    "print(\"\\nAuto-check for CQ3:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Check that median R² was computed\n",
    "assert 'median_r2' in locals(), \"Median R² not computed\"\n",
    "\n",
    "print(f\"Median R²: {median_r2:.4f} (threshold: >0.80)\")\n",
    "\n",
    "if median_r2 > 0.80:\n",
    "    print(\"✓ PASS: Fourier basis explains >80% of variance\")\n",
    "    if median_r2 > 0.84:\n",
    "        print(\"✓ EXCELLENT: Exceeds documented performance (0.84)\")\n",
    "else:\n",
    "    print(\"✗ FAIL: Fourier basis does not explain sufficient variance\")\n",
    "\n",
    "print(\"-\" * 40)\n",
    "print(f\"Expected: R² > 0.80\")\n",
    "print(f\"Achieved: R² = {median_r2:.4f}\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
