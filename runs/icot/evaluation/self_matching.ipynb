{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4007e049",
   "metadata": {},
   "source": [
    "# Self-Matching Evaluation Report\n",
    "## ICoT Multiplication Circuit Analysis\n",
    "\n",
    "**Date:** 2025-11-20  \n",
    "**Repository:** `/home/smallyan/critic_model_mechinterp/icot`  \n",
    "**Evaluator:** Automated Circuit Analysis System\n",
    "\n",
    "---\n",
    "\n",
    "## Executive Summary\n",
    "\n",
    "This report evaluates the internal consistency and correctness of the ICoT (Implicit Chain-of-Thought) multiplication reverse-engineering project.\n",
    "\n",
    "**Key Finding:** The repository does NOT contain a formal Plan file as typically expected. Therefore, this evaluation focuses on:\n",
    "1. Verifying mathematical correctness of implementations\n",
    "2. Testing internal consistency of code\n",
    "3. Checking if experiment scripts produce expected outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71290352",
   "metadata": {},
   "source": [
    "## 1. Repository Structure Analysis\n",
    "\n",
    "### Files and Organization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175697b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Set up paths\n",
    "repo_path = Path('/home/smallyan/critic_model_mechinterp/icot')\n",
    "os.chdir(repo_path.parent)\n",
    "sys.path.insert(0, str(repo_path))\n",
    "sys.path.insert(0, str(repo_path / 'src'))\n",
    "\n",
    "# Display repository structure\n",
    "print(\"Repository Structure:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "key_dirs = ['src', 'experiments', 'data', 'ckpts', 'paper_figures', 'icot_restructured']\n",
    "for dir_name in key_dirs:\n",
    "    dir_path = repo_path / dir_name\n",
    "    if dir_path.exists():\n",
    "        if dir_path.is_file():\n",
    "            print(f\"✓ {dir_name:20s} (file)\")\n",
    "        else:\n",
    "            file_count = len(list(dir_path.rglob('*.py'))) if dir_name in ['src', 'experiments'] else len(list(dir_path.iterdir()))\n",
    "            print(f\"✓ {dir_name:20s} ({file_count} items)\")\n",
    "    else:\n",
    "        print(f\"✗ {dir_name:20s} (missing)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd228477",
   "metadata": {},
   "source": [
    "## 2. Mathematical Correctness Verification\n",
    "\n",
    "### 2.1 Running Sum Calculation (c_hat)\n",
    "\n",
    "The core algorithm computes running sums for multiplication with carries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01536fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_c_hats(a, b):\n",
    "    \"\"\"Calculate running sums c_hat for multiplication a * b\"\"\"\n",
    "    c_hats = []\n",
    "    carrys = []\n",
    "    pair_sums = []\n",
    "    a_digits = [int(d) for d in str(a)[::-1]]  # Reverse to get LSD first\n",
    "    b_digits = [int(d) for d in str(b)[::-1]]\n",
    "    total_len = len(a_digits) + len(b_digits)\n",
    "\n",
    "    for ii in range(total_len):\n",
    "        aibi_sum = 0\n",
    "        # sum products along the \"diagonal\" ii\n",
    "        for a_ii in range(ii, -1, -1):\n",
    "            b_ii = ii - a_ii\n",
    "            if 0 <= a_ii < len(a_digits) and 0 <= b_ii < len(b_digits):\n",
    "                aibi_sum += a_digits[a_ii] * b_digits[b_ii]\n",
    "\n",
    "        pair_sums.append(aibi_sum)\n",
    "\n",
    "        # add carry from previous running sum\n",
    "        if len(c_hats) > 0:\n",
    "            aibi_sum += c_hats[-1] // 10\n",
    "\n",
    "        c_hats.append(aibi_sum)\n",
    "        carrys.append(aibi_sum // 10)\n",
    "\n",
    "    return c_hats, carrys, pair_sums\n",
    "\n",
    "# Test cases\n",
    "test_cases = [\n",
    "    (23, 45, 1035),\n",
    "    (99, 99, 9801),\n",
    "    (2365, 4347, 10280655),\n",
    "    (1234, 5678, 7006652),\n",
    "]\n",
    "\n",
    "print(\"Testing c_hat calculation:\")\n",
    "print(\"=\"*80)\n",
    "all_correct = True\n",
    "\n",
    "for a, b, expected in test_cases:\n",
    "    c_hats, carrys, pair_sums = get_c_hats(a, b)\n",
    "    result_digits = [c % 10 for c in c_hats]\n",
    "    result = int(''.join(str(d) for d in result_digits[::-1]))\n",
    "    \n",
    "    correct = (result == expected)\n",
    "    all_correct = all_correct and correct\n",
    "    status = \"✓\" if correct else \"✗\"\n",
    "    \n",
    "    print(f\"{status} {a:6d} × {b:6d} = {result:10d} (expected: {expected:10d})\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(f\"Overall: {'✓ ALL TESTS PASSED' if all_correct else '✗ SOME TESTS FAILED'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef8b331",
   "metadata": {},
   "source": [
    "## 3. Model Loading Verification\n",
    "\n",
    "### 3.1 Custom Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4716bc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from src.transformer import Transformer, TransformerConfig\n",
    "from transformers import GPT2Tokenizer\n",
    "\n",
    "# Load model\n",
    "config = TransformerConfig(\n",
    "    hidden_dim=768,\n",
    "    depth=2,\n",
    "    n_heads=4,\n",
    "    vocab_size=50257,\n",
    "    max_seq_len=128,\n",
    "    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    ")\n",
    "\n",
    "print(\"Loading ICoT model...\")\n",
    "model = Transformer(config)\n",
    "\n",
    "checkpoint_path = repo_path / 'ckpts/1_to_4_revops_2L_H4.pt'\n",
    "state_dict = torch.load(checkpoint_path, map_location='cpu', weights_only=False)\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "model.eval()\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "print(\"✓ Model loaded successfully\")\n",
    "print(f\"  Architecture: {config.depth}-layer, {config.n_heads}-head transformer\")\n",
    "print(f\"  Hidden dim: {config.hidden_dim}\")\n",
    "print(f\"  Vocab size: {config.vocab_size}\")\n",
    "print(f\"  Device: {next(model.parameters()).device}\")\n",
    "print(f\"  Parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a3acec",
   "metadata": {},
   "source": [
    "## 4. Data Processing Verification\n",
    "\n",
    "### 4.1 Output Digit Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baccb9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_utils import get_ci_from_operands\n",
    "\n",
    "print(\"Testing get_ci_from_operands:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Test extraction of individual digits\n",
    "a, b = 2365, 4347\n",
    "expected_product = a * b  # 10280655\n",
    "digits = [int(d) for d in str(expected_product)[::-1]]\n",
    "\n",
    "print(f\"Testing: {a} × {b} = {expected_product}\")\n",
    "print(f\"Expected digits (LSD-first): {digits}\\n\")\n",
    "\n",
    "all_correct = True\n",
    "for i in range(len(digits)):\n",
    "    ci = get_ci_from_operands(a, b, i)\n",
    "    expected = digits[i]\n",
    "    correct = (ci == expected)\n",
    "    all_correct = all_correct and correct\n",
    "    status = \"✓\" if correct else \"✗\"\n",
    "    print(f\"{status} c_{i} = {ci} (expected {expected})\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(f\"Overall: {'✓ ALL DIGITS CORRECT' if all_correct else '✗ SOME DIGITS INCORRECT'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba733f8",
   "metadata": {},
   "source": [
    "## 5. Output Verification\n",
    "\n",
    "### 5.1 Expected Figure Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af198e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if experiment outputs exist\n",
    "paper_figures_dir = repo_path / 'paper_figures'\n",
    "\n",
    "expected_outputs = {\n",
    "    'long_range_logit_attrib.py': 'long_term_effects_heatmap.pdf',\n",
    "    'probe_c_hat.py': 'c_hat_probe_new.pdf',\n",
    "    'grad_norms_and_losses.py': 'grad_norms_and_losses.pdf',\n",
    "}\n",
    "\n",
    "print(\"Checking expected experiment outputs:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for script, output_file in expected_outputs.items():\n",
    "    output_path = paper_figures_dir / output_file\n",
    "    exists = output_path.exists()\n",
    "    status = \"✓\" if exists else \"✗\"\n",
    "    \n",
    "    if exists:\n",
    "        size_mb = output_path.stat().st_size / (1024 * 1024)\n",
    "        print(f\"{status} {output_file:40s} ({size_mb:.2f} MB)\")\n",
    "    else:\n",
    "        print(f\"{status} {output_file:40s} (MISSING)\")\n",
    "\n",
    "# Count all figures\n",
    "all_figures = list(paper_figures_dir.glob('*.pdf'))\n",
    "print(\"=\"*80)\n",
    "print(f\"Total figures in paper_figures/: {len(all_figures)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df66ab85",
   "metadata": {},
   "source": [
    "## 6. Summary of Findings\n",
    "\n",
    "### 6.1 Mathematical Correctness\n",
    "- ✓ Running sum calculation (c_hat) is mathematically correct\n",
    "- ✓ Digit extraction function works correctly\n",
    "- ✓ Test cases pass for 2-digit, 4-digit multiplications\n",
    "\n",
    "### 6.2 Model Infrastructure\n",
    "- ✓ Model loads successfully from checkpoint\n",
    "- ✓ Architecture matches specification (2L4H)\n",
    "- ✓ Tokenizer properly configured\n",
    "\n",
    "### 6.3 Outputs\n",
    "- ✓ Key experiment outputs exist as PDF figures\n",
    "- ✓ 15 figures found in paper_figures directory\n",
    "\n",
    "### 6.4 Limitations\n",
    "\n",
    "**CRITICAL: This repository does NOT contain a formal Plan file.**\n",
    "\n",
    "As a result, this evaluation is limited to:\n",
    "- Verifying internal consistency\n",
    "- Checking mathematical correctness\n",
    "- Confirming outputs exist\n",
    "\n",
    "**Cannot evaluate:**\n",
    "- Whether results match stated goals (no plan provided)\n",
    "- Whether implementation follows a plan (no plan to reference)\n",
    "- Whether conclusions align with hypotheses (no formal hypotheses documented)\n",
    "\n",
    "### 6.5 Recommendation\n",
    "\n",
    "The code implementation appears mathematically sound and internally consistent. However, without a Plan file, it's impossible to evaluate whether the project achieves its stated objectives or follows its intended methodology."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
