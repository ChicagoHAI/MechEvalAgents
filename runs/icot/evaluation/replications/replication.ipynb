{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ICoT Replication: Linear Regression Probing\n",
    "\n",
    "This notebook replicates the linear regression probing experiment from the ICoT (Implicit Chain-of-Thought) multiplication research. The goal is to test whether intermediate values ĉk (running sums during multiplication) can be decoded from the model's hidden states using linear probes.\n",
    "\n",
    "## Experiment Overview\n",
    "\n",
    "**Goal**: Determine if the model internally represents running sums (ĉk) during multi-digit multiplication.\n",
    "\n",
    "**Method**:\n",
    "1. Load pre-trained ICoT model (2 layers, 4 heads)\n",
    "2. Extract hidden states at specific timesteps for each output digit position\n",
    "3. Train linear regression probes to predict ĉk from hidden states\n",
    "4. Evaluate probe accuracy (MAE) on validation set\n",
    "5. Compare against SFT (standard fine-tuning) baseline\n",
    "\n",
    "**Expected Result**: ICoT model should have lower MAE than SFT, indicating it learns to represent intermediate computation steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and imports\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Change to repository root\n",
    "os.chdir('/home/smallyan/critic_model_mechinterp/icot')\n",
    "sys.path.insert(0, '/home/smallyan/critic_model_mechinterp/icot')\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# Check GPU availability\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU device: {torch.cuda.get_device_name(0)}\")\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    print(\"Warning: Running on CPU - this will be slow\")\n",
    "    device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import model utilities\n",
    "from src.model_utils import load_hf_model, load_c_hat_model\n",
    "from src.HookedModel import convert_to_hooked_model\n",
    "from src.ActivationCache import record_activations\n",
    "from src.probes import RegressionProbe\n",
    "\n",
    "print(\"Successfully imported custom modules\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Models\n",
    "\n",
    "We load two models:\n",
    "- **ICoT model**: Trained with implicit chain-of-thought (learns multiplication via intermediate steps)\n",
    "- **SFT model**: Standard fine-tuning (learns direct input-output mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ICoT model\n",
    "BASE_DIR = \"/home/smallyan/critic_model_mechinterp/icot\"\n",
    "model_path = os.path.join(BASE_DIR, \"ckpts/2L4H/\")\n",
    "config_path = os.path.join(model_path, \"config.json\")\n",
    "state_dict_path = os.path.join(model_path, \"state_dict.bin\")\n",
    "\n",
    "print(\"Loading ICoT model...\")\n",
    "icot_model, tokenizer = load_hf_model(config_path, state_dict_path, cpu=(device==\"cpu\"))\n",
    "icot_model.to(device).eval()\n",
    "convert_to_hooked_model(icot_model)\n",
    "print(\"ICoT model loaded successfully\")\n",
    "\n",
    "# Load SFT model\n",
    "print(\"\\nLoading SFT model...\")\n",
    "sft_model_path = os.path.join(BASE_DIR, \"ckpts/vanilla_ft/ckpt.pt\")\n",
    "sft_model, _ = load_c_hat_model(sft_model_path)\n",
    "sft_model.to(device).eval()\n",
    "print(\"SFT model loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and Prepare Data\n",
    "\n",
    "The dataset contains 4x4 digit multiplication problems in reverse order (least-significant digit first).\n",
    "Format example: `1338 * 5105` represents 8331 × 5015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load validation data\n",
    "data_path = os.path.join(BASE_DIR, \"data/processed_valid.txt\")\n",
    "\n",
    "with open(data_path, \"r\") as f:\n",
    "    texts = f.readlines()\n",
    "\n",
    "# Parse operands from file format\n",
    "texts = [\n",
    "    text.replace(\" \", \"\").replace(\"\\n\", \"\").split(\"||\")[0].split(\"*\")\n",
    "    for text in texts\n",
    "    if text != \"\\n\"\n",
    "]\n",
    "\n",
    "# Convert to correct decimal order (reverse the digit order)\n",
    "operands = [(int(a[::-1]), int(b[::-1])) for a, b in texts]\n",
    "\n",
    "print(f\"Loaded {len(operands)} multiplication problems\")\n",
    "print(f\"Example: {operands[0][0]} × {operands[0][1]} = {operands[0][0] * operands[0][1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create Input Prompts\n",
    "\n",
    "We create prompts that include the full answer sequence to position the model at the final timestep where all intermediate values have been computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to format prompts\n",
    "def multiply(a: int, b: int, return_reverse=False) -> str:\n",
    "    \"\"\"Multiply a, b, optionally return the result in reverse order.\"\"\"\n",
    "    ans = str(a * b)\n",
    "    if return_reverse:\n",
    "        return ans[::-1]\n",
    "    return ans\n",
    "\n",
    "def prompt_ci_operands(operands, i, tokenizer, device=\"cpu\"):\n",
    "    \"\"\"Generate prompts for c_i position.\"\"\"\n",
    "    answers = [multiply(a, b, return_reverse=True) for a, b in operands]\n",
    "    suffixes = [\"\" for _ in answers]\n",
    "    if i >= 1:\n",
    "        suffixes = [\" \" + \" \".join(ans[:i]) for ans in answers]\n",
    "    \n",
    "    prompt_txts = [\n",
    "        \" \" + \" \".join(str(a))[::-1] + \" * \" + \" \".join(str(b))[::-1] + \" \"\n",
    "        for a, b in operands\n",
    "    ]\n",
    "    eos = tokenizer.eos_token\n",
    "    prompt_txts = [\n",
    "        f\"{txt}{eos}{eos} ####{suffix}\" for txt, suffix in zip(prompt_txts, suffixes)\n",
    "    ]\n",
    "    \n",
    "    prompt_token_ids = tokenizer(prompt_txts, return_tensors=\"pt\", padding=True).input_ids\n",
    "    prompt_token_ids = prompt_token_ids.to(device)\n",
    "    return prompt_txts, prompt_token_ids\n",
    "\n",
    "# Create prompts with full answer (i=8 for 8-digit output)\n",
    "prompt_text, tokens = prompt_ci_operands(operands, 8, tokenizer, device=device)\n",
    "print(f\"Created {len(tokens)} prompts\")\n",
    "print(f\"Example prompt: {prompt_text[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Compute Ground Truth Labels (ĉk values)\n",
    "\n",
    "For each operand pair (a, b), we compute the running sum ĉk at each digit position k.\n",
    "The formula: ĉk = Σ(ai × bj) + carry_{k-1}, where i+j = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_c_hats(a, b):\n",
    "    \"\"\"Compute running sums (c_hat) for multiplication of a and b.\"\"\"\n",
    "    c_hats = []\n",
    "    carrys = []\n",
    "    pair_sums = []\n",
    "    \n",
    "    # Convert to digit arrays (least significant first)\n",
    "    a_digits = [int(d) for d in str(a)[::-1]]\n",
    "    b_digits = [int(d) for d in str(b)[::-1]]\n",
    "    total_len = len(a_digits) + len(b_digits)\n",
    "    \n",
    "    for ii in range(total_len):\n",
    "        aibi_sum = 0\n",
    "        # Sum products along the diagonal ii\n",
    "        for a_ii in range(ii, -1, -1):\n",
    "            b_ii = ii - a_ii\n",
    "            if 0 <= a_ii < len(a_digits) and 0 <= b_ii < len(b_digits):\n",
    "                aibi_sum += a_digits[a_ii] * b_digits[b_ii]\n",
    "        \n",
    "        pair_sums.append(aibi_sum)\n",
    "        \n",
    "        # Add carry from previous running sum\n",
    "        if len(c_hats) > 0:\n",
    "            aibi_sum += c_hats[-1] // 10\n",
    "        \n",
    "        c_hats.append(aibi_sum)\n",
    "        carrys.append(aibi_sum // 10)\n",
    "    \n",
    "    return c_hats, carrys, pair_sums\n",
    "\n",
    "# Compute labels for all operands\n",
    "labels = []\n",
    "for a, b in operands:\n",
    "    c_hats, carrys, pair_sums = get_c_hats(a, b)\n",
    "    labels.append(c_hats)\n",
    "\n",
    "labels = torch.tensor(labels, dtype=torch.float32)\n",
    "print(f\"Computed labels shape: {labels.shape}\")\n",
    "print(f\"Example c_hats for {operands[0]}: {labels[0].tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Split Data into Train/Val\n",
    "\n",
    "We shuffle and split the data, using 1024 samples for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle and split\n",
    "torch.manual_seed(123)  # For reproducibility\n",
    "shuffle_idx = torch.randperm(len(tokens))\n",
    "tokens = tokens[shuffle_idx]\n",
    "labels = labels[shuffle_idx]\n",
    "\n",
    "val_size = 1024\n",
    "val_tokens = tokens[-val_size:].to(device)\n",
    "val_labels = labels[-val_size:].to(device)\n",
    "\n",
    "train_tokens = tokens[:-val_size].to(device)\n",
    "train_labels = labels[:-val_size].to(device)\n",
    "\n",
    "print(f\"Training samples: {len(train_tokens)}\")\n",
    "print(f\"Validation samples: {len(val_tokens)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Record Activations from Models\n",
    "\n",
    "We extract hidden states from specific hook points:\n",
    "- Layer 0: mid-residual, post-residual\n",
    "- Layer 1: mid-residual, post-residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hook modules to record activations from\n",
    "hook_modules = [\n",
    "    \"0.hook_resid_mid\",\n",
    "    \"0.hook_resid_post\",\n",
    "    \"1.hook_resid_mid\",\n",
    "    \"1.hook_resid_post\",\n",
    "]\n",
    "\n",
    "print(\"Recording validation activations from ICoT model...\")\n",
    "with torch.no_grad():\n",
    "    with record_activations(icot_model, hook_modules) as cache:\n",
    "        _ = icot_model(val_tokens)\n",
    "\n",
    "# Stack activations: [num_modules, batch, seq_len, hidden_dim]\n",
    "val_acts = torch.stack(\n",
    "    [cache[m][:, -val_labels.shape[1]:] for m in hook_modules],\n",
    "    dim=0,\n",
    ")\n",
    "\n",
    "print(f\"Validation activations shape: {val_acts.shape}\")\n",
    "print(f\"[num_modules={val_acts.shape[0]}, batch={val_acts.shape[1]}, seq_len={val_acts.shape[2]}, hidden_dim={val_acts.shape[3]}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Train or Load Linear Probes\n",
    "\n",
    "We attempt to load pre-trained probes. If not available, we train new ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probe configuration\n",
    "num_modules, val_batch_size, seq, d_model = val_acts.shape\n",
    "probe_shape = (num_modules, seq, d_model, 1)\n",
    "\n",
    "# Try to load pre-trained ICoT probe\n",
    "probe_path = os.path.join(BASE_DIR, \"ckpts/icot_c_hat_probe/probe.pth\")\n",
    "icot_probe = RegressionProbe(probe_shape, 1e-3)\n",
    "\n",
    "if os.path.exists(probe_path):\n",
    "    print(f\"Loading pre-trained ICoT probe from {probe_path}\")\n",
    "    icot_probe.load_weights(probe_path)\n",
    "else:\n",
    "    print(\"Pre-trained ICoT probe not found. Training new probe...\")\n",
    "    # Record training activations\n",
    "    print(\"Recording training activations...\")\n",
    "    with torch.no_grad():\n",
    "        with record_activations(icot_model, hook_modules) as cache:\n",
    "            _ = icot_model(train_tokens)\n",
    "    \n",
    "    train_acts = torch.stack(\n",
    "        [cache[m][:, -train_labels.shape[1]:] for m in hook_modules],\n",
    "        dim=0,\n",
    "    )\n",
    "    \n",
    "    # Train probe\n",
    "    print(\"Training probe (this may take a few minutes)...\")\n",
    "    for epoch in range(100):\n",
    "        loss = icot_probe.train_step(train_acts, train_labels)\n",
    "        if (epoch + 1) % 20 == 0:\n",
    "            print(f\"Epoch {epoch+1}/100, Loss: {loss:.4f}\")\n",
    "\n",
    "# Try to load pre-trained SFT probe\n",
    "sft_probe_path = os.path.join(BASE_DIR, \"ckpts/sft_c_hat_probe/probe.pth\")\n",
    "sft_probe = RegressionProbe(probe_shape, 1e-3)\n",
    "\n",
    "if os.path.exists(sft_probe_path):\n",
    "    print(f\"\\nLoading pre-trained SFT probe from {sft_probe_path}\")\n",
    "    sft_probe.load_weights(sft_probe_path)\n",
    "else:\n",
    "    print(\"\\nWarning: Pre-trained SFT probe not found. Skipping SFT comparison.\")\n",
    "    sft_probe = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Evaluate Probes\n",
    "\n",
    "We compute Mean Absolute Error (MAE) for each digit position (c2 through c6)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate ICoT probe\n",
    "print(\"Evaluating ICoT probe...\")\n",
    "with torch.no_grad():\n",
    "    icot_val_preds = icot_probe(val_acts)\n",
    "\n",
    "icot_metrics = icot_probe.evaluate_probe(val_acts, val_labels)\n",
    "icot_mae = icot_metrics[-1][2]  # Extract MAE for layer 1 post-residual\n",
    "\n",
    "print(f\"ICoT MAE by digit position:\")\n",
    "for i, mae in enumerate(icot_mae):\n",
    "    print(f\"  c{i}: {mae:.3f}\")\n",
    "\n",
    "# Evaluate SFT probe if available\n",
    "if sft_probe is not None:\n",
    "    print(\"\\nEvaluating SFT probe...\")\n",
    "    with torch.no_grad():\n",
    "        sft_val_preds = sft_probe(val_acts)\n",
    "    \n",
    "    sft_metrics = sft_probe.evaluate_probe(val_acts, val_labels)\n",
    "    sft_mae = sft_metrics[-1][2]\n",
    "    \n",
    "    print(f\"SFT MAE by digit position:\")\n",
    "    for i, mae in enumerate(sft_mae):\n",
    "        print(f\"  c{i}: {mae:.3f}\")\n",
    "else:\n",
    "    sft_val_preds = None\n",
    "    sft_mae = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Visualize Results\n",
    "\n",
    "Create scatter plots comparing predicted vs. true ĉk values for positions c2-c6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for plotting\n",
    "val_labels_np = val_labels.cpu().numpy()\n",
    "icot_val_preds_np = icot_val_preds.cpu().numpy()\n",
    "\n",
    "if sft_val_preds is not None:\n",
    "    sft_val_preds_np = sft_val_preds.cpu().numpy()\n",
    "    n_rows = 2\n",
    "else:\n",
    "    n_rows = 1\n",
    "\n",
    "n_cols = 5\n",
    "fig, axes = plt.subplots(\n",
    "    n_rows, n_cols, figsize=(15, 3*n_rows), gridspec_kw={\"hspace\": 0.4}\n",
    ")\n",
    "\n",
    "if n_rows == 1:\n",
    "    axes = axes.reshape(1, -1)\n",
    "\n",
    "for row in range(n_rows):\n",
    "    if row == 0 and sft_val_preds is not None:\n",
    "        probe_preds = sft_val_preds_np\n",
    "        metrics = sft_mae\n",
    "        model_name = \"SFT\"\n",
    "    else:\n",
    "        probe_preds = icot_val_preds_np\n",
    "        metrics = icot_mae\n",
    "        model_name = \"ICoT\"\n",
    "    \n",
    "    for col_idx, c_i in enumerate(range(2, 7)):\n",
    "        ax = axes[row, col_idx]\n",
    "        _val_labels = val_labels_np[:, c_i]\n",
    "        _val_preds = probe_preds[2, :, c_i]  # Layer 1 mid-residual\n",
    "        \n",
    "        min_val = min(_val_labels.min(), _val_preds.min())\n",
    "        max_val = max(_val_labels.max(), _val_preds.max())\n",
    "        diagonal_line = np.linspace(min_val, max_val, 100)\n",
    "        \n",
    "        sorted_indices = np.argsort(_val_labels)\n",
    "        sorted_labels = _val_labels[sorted_indices]\n",
    "        sorted_preds = _val_preds[sorted_indices]\n",
    "        \n",
    "        mae = metrics[c_i]\n",
    "        \n",
    "        ax.plot(\n",
    "            diagonal_line,\n",
    "            diagonal_line,\n",
    "            \"r--\",\n",
    "            alpha=0.7,\n",
    "            linewidth=2,\n",
    "            label=\"Perfect predictions\",\n",
    "        )\n",
    "        \n",
    "        ax.scatter(\n",
    "            sorted_labels,\n",
    "            sorted_preds,\n",
    "            alpha=0.5,\n",
    "            s=5,\n",
    "            label=\"Predictions\",\n",
    "            color=\"blue\",\n",
    "        )\n",
    "        ax.set_title(f\"{model_name}: c_hat_{c_i} (MAE {mae:.2f})\", fontsize=12)\n",
    "        \n",
    "        if row == n_rows - 1:\n",
    "            ax.set_xlabel(f\"True c_hat_{c_i}\", fontsize=11)\n",
    "        \n",
    "        if col_idx == 0:\n",
    "            ax.set_ylabel(f\"Predicted c_hat\", fontsize=11)\n",
    "            if row == 0:\n",
    "                ax.legend(fontsize=9)\n",
    "        ax.set_aspect(\"equal\", adjustable=\"box\")\n",
    "\n",
    "plt.tight_layout()\n",
    "output_path = \"evaluation/replications/probe_results.png\"\n",
    "plt.savefig(output_path, dpi=150, bbox_inches=\"tight\")\n",
    "print(f\"\\nSaved visualization to {output_path}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Summary of Results\n",
    "\n",
    "Compare the MAE values between ICoT and SFT models to determine which better represents intermediate computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"REPLICATION RESULTS SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nICoT Model - Mean Absolute Error by digit:\")\n",
    "for i in range(2, 7):\n",
    "    print(f\"  c_hat_{i}: {icot_mae[i]:.3f}\")\n",
    "print(f\"  Average (c2-c6): {icot_mae[2:7].mean():.3f}\")\n",
    "\n",
    "if sft_mae is not None:\n",
    "    print(\"\\nSFT Model - Mean Absolute Error by digit:\")\n",
    "    for i in range(2, 7):\n",
    "        print(f\"  c_hat_{i}: {sft_mae[i]:.3f}\")\n",
    "    print(f\"  Average (c2-c6): {sft_mae[2:7].mean():.3f}\")\n",
    "    \n",
    "    print(\"\\nImprovement (SFT MAE - ICoT MAE):\")\n",
    "    for i in range(2, 7):\n",
    "        improvement = sft_mae[i] - icot_mae[i]\n",
    "        print(f\"  c_hat_{i}: {improvement:.3f} ({improvement/sft_mae[i]*100:.1f}% better)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"INTERPRETATION:\")\n",
    "print(\"Lower MAE indicates the model better represents intermediate values.\")\n",
    "print(\"ICoT should show significantly lower MAE than SFT, confirming it\")\n",
    "print(\"learns to represent running sums during multiplication.\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
