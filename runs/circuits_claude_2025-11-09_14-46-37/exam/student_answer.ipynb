{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbb3b678",
   "metadata": {
    "execution_status": "complete"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /home/smallyan/critic_model_mechinterp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "CUDA device: NVIDIA A100 80GB PCIe\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('/home/smallyan/critic_model_mechinterp')\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n",
    "\n",
    "# Check if CUDA is available\n",
    "import torch\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5b0577",
   "metadata": {},
   "source": [
    "# IOI Circuit Analysis Exam - Student Answers\n",
    "\n",
    "Student: Claude (AI Student)  \n",
    "Date: 2025-11-14  \n",
    "Documentation Source: `/home/smallyan/critic_model_mechinterp/runs/circuits_claude_2025-11-09_14-46-37/logs/documentation.md`\n",
    "\n",
    "---\n",
    "\n",
    "## Part 1: Factual Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08770009",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "**Question:** What is the primary goal of the IOI (Indirect Object Identification) task?\n",
    "\n",
    "**Options:**\n",
    "- A. To predict the indirect object at the end of a sentence where two names appear, with one name repeated.\n",
    "- B. To identify which subject performed an action in a sentence.\n",
    "- C. To determine the direct object being transferred in a sentence.\n",
    "- D. To classify whether a sentence contains duplicate tokens.\n",
    "\n",
    "**Reasoning:**\n",
    "According to Section 1 (Goal) of the documentation, the research objective is to \"Identify a precise circuit in GPT2-small that implements the **Indirect Object Identification (IOI)** behavior.\" Section 2 (Data) explicitly states that the task is to \"Predict the indirect object at the end of a sentence\" and provides the example structure where two names appear with one being repeated (the subject S appears at S1 and S2, while the indirect object IO appears once). The correct answer must be the one that predicts the indirect object in a sentence with two names where one is repeated.\n",
    "\n",
    "**Answer:** A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6311a1f",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "**Question:** In the example sentence 'As Carl and Maria left the consulate, Carl gave a fridge to ___', what are the positions S1, S2, and IO respectively?\n",
    "\n",
    "**Options:**\n",
    "- A. S1 = position 2 (first 'Carl'), S2 = position 9 (second 'Carl'), IO = position 4 ('Maria')\n",
    "- B. S1 = position 4 ('Maria'), S2 = position 9 (second 'Carl'), IO = position 2 (first 'Carl')\n",
    "- C. S1 = position 2 (first 'Carl'), S2 = position 4 ('Maria'), IO = position 9 (second 'Carl')\n",
    "- D. S1 = position 9 (second 'Carl'), S2 = position 2 (first 'Carl'), IO = position 13 ('to')\n",
    "\n",
    "**Reasoning:**\n",
    "Section 2 (Data) under \"Example Sentence Structure\" provides this exact example and explicitly states:\n",
    "- \"**S1**: First mention of subject (position 2: 'Carl')\"\n",
    "- \"**S2**: Second mention of subject (position 9: 'Carl')\"\n",
    "- \"**IO**: Indirect object (position 4: 'Maria')\"\n",
    "- \"**END**: Final position (position 13: 'to')\"\n",
    "\n",
    "The documentation clearly identifies S1 as the first Carl at position 2, S2 as the second Carl at position 9, and IO as Maria at position 4.\n",
    "\n",
    "**Answer:** A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3a1357",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "**Question:** Describe the three functional components hypothesized to comprise the IOI circuit, including what positions they attend from/to and their proposed function.\n",
    "\n",
    "**Reasoning:**\n",
    "Section 1 (Goal) under \"Hypothesis\" explicitly lists the three functional components. Section 3.3 (Analysis Pipeline) Step 2 provides detailed descriptions of the attention patterns for each component type.\n",
    "\n",
    "Based on the documentation:\n",
    "\n",
    "1. **Duplicate Token Heads**: These heads are active at position S2 and attend to position S1. Their function is to signal token duplication through position features. The documentation describes them as having \"S2 → S1 attention\" and states they detect when a token appears twice in the sequence.\n",
    "\n",
    "2. **S-Inhibition Heads**: These heads are active at the END position and attend to position S2. Their function is to inhibit Name-Mover attention to subject positions. The documentation describes them as having \"END → S2 attention\" and they work to suppress attention to the subject (which would be the wrong answer).\n",
    "\n",
    "3. **Name-Mover Heads**: These heads are active at the END position and attend to the IO position. Their function is to copy the indirect object token to the residual stream for final prediction. The documentation describes them as having \"END → IO attention\" and they are responsible for moving the correct answer (the indirect object) to the output.\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "The three functional components are:\n",
    "\n",
    "1. **Duplicate Token Heads**: Attend from S2 → S1; detect and signal token duplication through position features\n",
    "2. **S-Inhibition Heads**: Attend from END → S2; inhibit Name-Mover attention to subject positions  \n",
    "3. **Name-Mover Heads**: Attend from END → IO; copy the indirect object token to the residual stream for prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f929f8e6",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "**Question:** How many dimensions does each attention head write to the residual stream in GPT2-small?\n",
    "\n",
    "**Options:**\n",
    "- A. 64 dimensions\n",
    "- B. 768 dimensions\n",
    "- C. 3,072 dimensions\n",
    "- D. 12 dimensions\n",
    "\n",
    "**Reasoning:**\n",
    "Section 3.2 (Write Budget Constraints) explicitly states: \"Each attention head writes: 64 dimensions (d_model / n_heads)\". This is further confirmed in Section 3.1 (Model Configuration) which lists:\n",
    "- d_model: 768\n",
    "- Heads per layer: 12\n",
    "- d_head: 64\n",
    "\n",
    "The calculation is: d_model / n_heads = 768 / 12 = 64 dimensions per head.\n",
    "\n",
    "**Answer:** A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee56ecfc",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "\n",
    "**Question:** What was the baseline accuracy of GPT2-small on the IOI task (100 example sample)?\n",
    "\n",
    "**Options:**\n",
    "- A. 94.00%\n",
    "- B. 87.50%\n",
    "- C. 99.00%\n",
    "- D. 72.00%\n",
    "\n",
    "**Reasoning:**\n",
    "Section 3.3 (Analysis Pipeline) Step 1: Baseline Evaluation explicitly states:\n",
    "\"**Result**: 94.00% accuracy (94/100 correct)\"\n",
    "\n",
    "This is also confirmed in Section 4 (Results) under \"Performance Metrics\" which states:\n",
    "\"**Baseline Model Accuracy**: 94.00% (94/100 examples)\"\n",
    "\n",
    "**Answer:** A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ffb224",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "\n",
    "**Question:** Which attention head showed the highest average attention from S2 to S1 (Duplicate Token Head behavior)?\n",
    "\n",
    "**Options:**\n",
    "- A. a3.h0 (0.7191)\n",
    "- B. a1.h11 (0.6613)\n",
    "- C. a8.h6 (0.7441)\n",
    "- D. a9.h9 (0.7998)\n",
    "\n",
    "**Reasoning:**\n",
    "Section 3.3 (Analysis Pipeline) Step 2: Attention Pattern Analysis under \"Duplicate Token Heads (S2 → S1 attention)\" lists the top 5 heads:\n",
    "1. a3.h0: 0.7191\n",
    "2. a1.h11: 0.6613\n",
    "3. a0.h5: 0.6080\n",
    "4. a0.h1: 0.5152\n",
    "5. a0.h10: 0.2359\n",
    "\n",
    "The highest average attention from S2 to S1 is head a3.h0 with 0.7191. Note that a8.h6 (0.7441) is the top S-Inhibition head (END → S2), and a9.h9 (0.7998) is the top Name-Mover head (END → IO), not Duplicate Token heads.\n",
    "\n",
    "**Answer:** A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa7eacb",
   "metadata": {},
   "source": [
    "### Question 7\n",
    "\n",
    "**Question:** Which attention head showed the highest average attention from END to IO (Name-Mover Head behavior)?\n",
    "\n",
    "**Options:**\n",
    "- A. a9.h9 (0.7998)\n",
    "- B. a10.h7 (0.7829)\n",
    "- C. a9.h6 (0.7412)\n",
    "- D. a8.h6 (0.7441)\n",
    "\n",
    "**Reasoning:**\n",
    "Section 3.3 (Analysis Pipeline) Step 2: Attention Pattern Analysis under \"Name-Mover Heads (END → IO attention)\" lists the top 5 heads:\n",
    "1. a9.h9: 0.7998\n",
    "2. a10.h7: 0.7829\n",
    "3. a9.h6: 0.7412\n",
    "4. a11.h10: 0.6369\n",
    "5. a10.h0: 0.3877\n",
    "\n",
    "The highest average attention from END to IO is head a9.h9 with 0.7998. This is also mentioned in Section 5 (Analysis) under \"Key Observations\" where it states that top Name-Mover heads show \"a9.h9 with 0.80 avg attention.\"\n",
    "\n",
    "**Answer:** A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7511ef7",
   "metadata": {},
   "source": [
    "### Question 8\n",
    "\n",
    "**Question:** How many total nodes (including input, attention heads, and MLPs) are in the final identified circuit?\n",
    "\n",
    "**Options:**\n",
    "- A. 44 nodes (1 input + 31 heads + 12 MLPs)\n",
    "- B. 43 nodes (31 heads + 12 MLPs)\n",
    "- C. 31 nodes (attention heads only)\n",
    "- D. 55 nodes (1 input + 31 heads + 12 MLPs + 11 additional)\n",
    "\n",
    "**Reasoning:**\n",
    "Section 4 (Results) under \"Final Circuit Composition\" explicitly states:\n",
    "\"**Total Nodes**: 44\n",
    "- 1 input node\n",
    "- 31 attention heads\n",
    "- 12 MLPs\"\n",
    "\n",
    "This is the arithmetic: 1 + 31 + 12 = 44 total nodes.\n",
    "\n",
    "**Answer:** A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4153911",
   "metadata": {},
   "source": [
    "### Question 9\n",
    "\n",
    "**Question:** Explain why the identified circuit exhibits 'layered processing' and what functional role each layer group plays in the IOI task.\n",
    "\n",
    "**Reasoning:**\n",
    "Section 5 (Analysis) under \"Key Observations\" point 1 states: \"**Layered Processing**: The circuit exhibits clear stratification\" and lists three distinct layer groups with their functions:\n",
    "- Early layers (0-3): Duplicate token detection\n",
    "- Middle layers (7-8): Subject inhibition\n",
    "- Late layers (9-11): Name moving and prediction\n",
    "\n",
    "Section 5 also under \"Support for Hypothesis\" provides additional detail about why this layering makes sense functionally, stating that Duplicate Token heads are \"predominantly in early-to-middle layers (0, 1, 3), consistent with positional feature detection,\" S-Inhibition heads are \"in middle-to-late layers (7, 8, 9), appropriate for suppressing subject interference,\" and Name-Mover heads are \"concentrated in late layers (9, 10, 11), ideal for final token prediction.\"\n",
    "\n",
    "The documentation also states in the Main Takeaways (Section 7, point 3) that \"The circuit exhibits clear layered processing, with early layers detecting patterns, middle layers inhibiting interference, and late layers performing final prediction.\"\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "The circuit exhibits 'layered processing' because different functional components are concentrated in different layers of the model, creating a hierarchical pipeline:\n",
    "\n",
    "1. **Early layers (0-3)**: Perform duplicate token detection. These layers identify that the subject token appears twice in the sequence (S1 and S2 positions) and extract positional features.\n",
    "\n",
    "2. **Middle layers (7-8)**: Handle subject inhibition. These layers suppress attention to the subject positions to prevent the model from incorrectly predicting the subject instead of the indirect object.\n",
    "\n",
    "3. **Late layers (9-11)**: Execute name moving and final prediction. These layers attend to the indirect object position and copy that token to the residual stream for the final output prediction.\n",
    "\n",
    "This stratification shows that the IOI task is solved through a sequential computational pipeline where each layer group builds on the previous processing stage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70be3e1",
   "metadata": {},
   "source": [
    "### Question 10\n",
    "\n",
    "**Question:** The documentation states that the circuit achieves 100% budget utilization with exactly 11,200 dimensions. If the researchers wanted to add 5 more attention heads to the circuit, how many MLPs would they need to remove to stay within budget? Show your calculation.\n",
    "\n",
    "**Reasoning:**\n",
    "From Section 3.2 (Write Budget Constraints):\n",
    "- Each attention head writes: 64 dimensions\n",
    "- Each MLP writes: 768 dimensions\n",
    "- Total budget: ≤ 11,200 dimensions\n",
    "\n",
    "Current circuit (from Section 4):\n",
    "- 31 attention heads × 64 = 1,984 dimensions\n",
    "- 12 MLPs × 768 = 9,216 dimensions\n",
    "- Total = 11,200 dimensions (100% utilization)\n",
    "\n",
    "Calculation:\n",
    "- Adding 5 attention heads adds: 5 × 64 = 320 dimensions\n",
    "- New budget requirement: 11,200 + 320 = 11,520 dimensions\n",
    "- Amount over budget: 11,520 - 11,200 = 320 dimensions\n",
    "- MLPs to remove: 320 ÷ 768 = 0.4167 MLPs\n",
    "\n",
    "Since we cannot remove a fractional MLP, we must round up to remove 1 complete MLP.\n",
    "- Removing 1 MLP frees: 1 × 768 = 768 dimensions\n",
    "- New total with +5 heads and -1 MLP: 11,200 + 320 - 768 = 10,752 dimensions\n",
    "- This is within budget (≤ 11,200) ✓\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "To add 5 attention heads while staying within the 11,200 dimension budget:\n",
    "\n",
    "**Calculation:**\n",
    "- 5 additional heads × 64 dims/head = 320 additional dimensions needed\n",
    "- 320 dimensions ÷ 768 dims/MLP = 0.4167 MLPs\n",
    "- Since MLPs are indivisible units, we must remove at least 1 MLP\n",
    "\n",
    "**Answer: 1 MLP must be removed**\n",
    "\n",
    "Verification:\n",
    "- Original: 31 heads + 12 MLPs = 1,984 + 9,216 = 11,200 dims\n",
    "- Modified: 36 heads + 11 MLPs = 2,304 + 8,448 = 10,752 dims ✓ (within budget)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4845794b",
   "metadata": {},
   "source": [
    "### Question 11\n",
    "\n",
    "**Question:** Why does the documentation suggest that finding multiple heads per functional category indicates 'robustness through redundancy'?\n",
    "\n",
    "**Options:**\n",
    "- A. Multiple heads performing similar functions provide backup pathways, so if one head fails or is ablated, others can compensate, making the circuit more resilient to perturbations.\n",
    "- B. Having more heads increases the total budget utilization, making the circuit more efficient.\n",
    "- C. Redundant heads allow the model to process multiple sentences in parallel.\n",
    "- D. Multiple heads with the same function indicate that the circuit was overfit to the training data.\n",
    "\n",
    "**Reasoning:**\n",
    "Section 5 (Analysis) under \"Key Observations\" point 4 states:\n",
    "\"**Redundancy**: Multiple heads per category suggest robustness through redundancy, which is common in neural networks\"\n",
    "\n",
    "The concept of \"robustness through redundancy\" in neural networks refers to having multiple components that can perform similar functions, so that the system remains functional even if some components are damaged or removed. This is a well-established principle in neural network architecture. Option A correctly describes this concept - multiple heads provide backup pathways that can compensate if individual heads fail or are ablated (removed).\n",
    "\n",
    "Options B, C, and D are not supported by the documentation and do not align with the standard meaning of \"robustness through redundancy\" in neural network contexts.\n",
    "\n",
    "**Answer:** A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf14f599",
   "metadata": {},
   "source": [
    "### Question 12\n",
    "\n",
    "**Question:** Based on the methodology described, propose a concrete experiment to test whether the S-Inhibition Heads are causally necessary for the IOI task. What would you measure and what result would confirm their necessity?\n",
    "\n",
    "**Reasoning:**\n",
    "Section 6 (Next Steps) under \"Potential Extensions\" suggests several experimental approaches:\n",
    "1. \"**Ablation Studies**: Remove individual heads or head categories to measure performance impact\"\n",
    "3. \"**Activation Patching**: Directly test causal role of each component\"\n",
    "\n",
    "The documentation's hypothesis (Section 1) states that S-Inhibition Heads work by \"inhibiting Name-Mover attention to subject positions\" (attending from END → S2). Section 5 describes these heads as being responsible for \"suppressing subject interference.\"\n",
    "\n",
    "Based on this methodology, an ablation study would be the most direct way to test causal necessity. The key measurement would be whether the model starts predicting the subject (S) instead of the indirect object (IO) when S-Inhibition heads are removed, since these heads are hypothesized to suppress attention to the subject.\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "**Proposed Experiment: Ablation Study of S-Inhibition Heads**\n",
    "\n",
    "**Procedure:**\n",
    "1. Identify all 12 S-Inhibition heads in the circuit (those with strong END → S2 attention, particularly a8.h6, a7.h9, a8.h10, a8.h5, and a9.h7)\n",
    "2. Run the model on the 100 IOI test examples with these heads ablated (set their outputs to zero or remove them from the circuit)\n",
    "3. Evaluate model predictions and compare to baseline performance\n",
    "\n",
    "**Measurements:**\n",
    "- Overall accuracy on IOI task (baseline: 94%)\n",
    "- Specifically measure how often the model incorrectly predicts the subject (S) instead of the indirect object (IO)\n",
    "- Compare logit differences between IO and S tokens (with vs. without S-Inhibition heads)\n",
    "\n",
    "**Expected Results if S-Inhibition Heads are Causally Necessary:**\n",
    "- Accuracy should drop significantly below the 94% baseline\n",
    "- The model should show increased incorrect predictions of the subject token (S)\n",
    "- The logit advantage for IO over S should decrease or reverse, indicating the model is no longer properly suppressing subject interference\n",
    "\n",
    "This would confirm that S-Inhibition heads are causally necessary for preventing the model from incorrectly attending to and predicting the repeated subject token."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37a8334",
   "metadata": {},
   "source": [
    "### Question 13\n",
    "\n",
    "**Question:** The circuit uses only 11,200 of 110,592 possible dimensions (10.1% of total model capacity). What does this suggest about how GPT2-small implements the IOI behavior?\n",
    "\n",
    "**Options:**\n",
    "- A. IOI is implemented by a relatively sparse, specialized subcircuit rather than requiring the full model capacity, suggesting modular functional organization.\n",
    "- B. The model is inefficient and wastes 90% of its capacity on irrelevant computations.\n",
    "- C. IOI is a simple task that doesn't require sophisticated neural processing.\n",
    "- D. The remaining 90% of capacity is used for error correction and robustness.\n",
    "\n",
    "**Reasoning:**\n",
    "Section 7 (Main Takeaways) point 5 explicitly states:\n",
    "\"**Efficient Representation**: The circuit uses only 11,200 of 110,592 possible dimensions (10.1% of total model capacity), suggesting IOI is implemented by a relatively sparse subcircuit\"\n",
    "\n",
    "The documentation emphasizes that this finding suggests \"modular functional organization\" where specific tasks are handled by specialized subcircuits rather than requiring the entire model. This is a key finding about neural network interpretability - complex behaviors can be localized to specific components.\n",
    "\n",
    "Options B, C, and D are not supported by the documentation. The documentation does not suggest the model is inefficient (B), does not characterize IOI as simple (it identifies complex multi-component processing), and does not discuss error correction in the remaining capacity (D).\n",
    "\n",
    "**Answer:** A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bafc24",
   "metadata": {},
   "source": [
    "### Question 14\n",
    "\n",
    "**Question:** Suppose you found a new attention head a5.h7 that shows strong attention from END to S1 (not S2). How would you classify this head relative to the three hypothesized categories, and what function might it serve?\n",
    "\n",
    "**Reasoning:**\n",
    "The documentation describes three functional categories based on their attention patterns:\n",
    "1. **Duplicate Token Heads**: S2 → S1 attention\n",
    "2. **S-Inhibition Heads**: END → S2 attention  \n",
    "3. **Name-Mover Heads**: END → IO attention\n",
    "\n",
    "A head with END → S1 attention does not fit any of the three hypothesized categories. However, Section 6 (Next Steps) under \"Alternative Hypotheses to Explore\" mentions:\n",
    "\"**Negative Name Movers**: Heads that move S tokens to suppress them\"\n",
    "\n",
    "Since S1 is the first occurrence of the subject token (which should NOT be the answer), a head attending from END → S1 could potentially be involved in suppressing or inhibiting the subject. This would be similar to S-Inhibition heads but targeting S1 instead of S2.\n",
    "\n",
    "The documentation does not explicitly describe END → S1 heads, so this requires inference based on the functional logic of the task. Since both S1 and S2 are subject positions that need to be suppressed in favor of the IO, a head attending to S1 could serve an inhibitory function.\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "The head a5.h7 (END → S1 attention) does not fit into any of the three hypothesized categories (Duplicate Token, S-Inhibition, or Name-Mover).\n",
    "\n",
    "**Classification:** This would likely be a variant of an inhibition head, possibly what the documentation refers to as a \"Negative Name Mover\" in the alternative hypotheses section.\n",
    "\n",
    "**Proposed Function:** Since S1 is the first mention of the subject (which is the incorrect answer for IOI), this head might serve to suppress or inhibit attention to the first subject position. This would complement the S-Inhibition heads (which suppress S2) by ensuring that neither subject position is selected as the final answer.\n",
    "\n",
    "Alternatively, this head could be part of a backup pathway that helps distinguish between S1 and S2 positions, or it could be involved in the early detection phase by identifying the first occurrence of the repeated name.\n",
    "\n",
    "To determine its true function, the documentation's methodology suggests performing ablation studies or activation patching experiments on this head."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881b344d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Code-Based Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76e06a1",
   "metadata": {},
   "source": [
    "### Question 15 (CQ1): Budget Constraint Verification and Component Analysis\n",
    "\n",
    "**Question:** Write code to verify the budget constraint calculation. Given the final circuit composition (31 attention heads and 12 MLPs), compute the total dimensional write and verify it equals 11,200. Also calculate what percentage of the budget is used by attention heads vs MLPs.\n",
    "\n",
    "**Reference:** Section 3.2 (Write Budget Constraints) and Section 4 (Budget Verification table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6318ae4",
   "metadata": {
    "execution_status": "complete"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention heads: 1984 dimensions (17.71%)\n",
      "MLPs: 9216 dimensions (82.29%)\n",
      "Total budget: 11200 dimensions\n",
      "Budget constraint (≤11,200): PASS\n"
     ]
    }
   ],
   "source": [
    "# Calculate the budget for the IOI circuit\n",
    "# Given information:\n",
    "# - 31 attention heads in the circuit\n",
    "# - 12 MLPs in the circuit\n",
    "# - Each attention head writes: d_model / n_heads = 768 / 12 = 64 dimensions\n",
    "# - Each MLP writes: d_model = 768 dimensions\n",
    "\n",
    "# Calculate total dimensions written by attention heads\n",
    "n_heads = 31\n",
    "dims_per_head = 64\n",
    "total_head_dims = n_heads * dims_per_head\n",
    "\n",
    "# Calculate total dimensions written by MLPs\n",
    "n_mlps = 12\n",
    "dims_per_mlp = 768\n",
    "total_mlp_dims = n_mlps * dims_per_mlp\n",
    "\n",
    "# Calculate total budget\n",
    "total_budget = total_head_dims + total_mlp_dims\n",
    "\n",
    "# Calculate percentages\n",
    "head_percentage = (total_head_dims / total_budget) * 100\n",
    "mlp_percentage = (total_mlp_dims / total_budget) * 100\n",
    "\n",
    "# Print results\n",
    "print(f\"Attention heads: {total_head_dims} dimensions ({head_percentage:.2f}%)\")\n",
    "print(f\"MLPs: {total_mlp_dims} dimensions ({mlp_percentage:.2f}%)\")\n",
    "print(f\"Total budget: {total_budget} dimensions\")\n",
    "print(f\"Budget constraint (≤11,200): {'PASS' if total_budget <= 11200 else 'FAIL'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b2352d",
   "metadata": {},
   "source": [
    "**Reasoning:**\n",
    "Based on the documentation (Section 3.2 and Section 4):\n",
    "- Each attention head writes 64 dimensions (d_model / n_heads = 768 / 12)\n",
    "- Each MLP writes 768 dimensions (d_model)\n",
    "- The final circuit has 31 attention heads and 12 MLPs\n",
    "\n",
    "The calculation verifies that:\n",
    "- 31 heads × 64 dims = 1,984 dimensions (17.71% of budget)\n",
    "- 12 MLPs × 768 dims = 9,216 dimensions (82.29% of budget)\n",
    "- Total = 11,200 dimensions (exactly at the budget limit)\n",
    "\n",
    "This matches the Budget Verification table in Section 4 of the documentation.\n",
    "\n",
    "**Answer:** The circuit achieves exactly 11,200 dimensions with 100% budget utilization. Attention heads use 1,984 dims (17.71%) and MLPs use 9,216 dims (82.29%). Budget constraint verification: PASS ✓"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7613f50b",
   "metadata": {},
   "source": [
    "### Question 16 (CQ2): Layer Distribution Analysis of Attention Heads\n",
    "\n",
    "**Question:** Write code to analyze the layer distribution of the 31 attention heads in the circuit. Count how many heads are in each layer (0-11) and identify which layer has the most heads. Then determine if there's a trend showing more heads in later layers.\n",
    "\n",
    "**Reference:** Section 4 (Results) - Layer Distribution and Section 5 - layered processing observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d511b0a",
   "metadata": {
    "execution_status": "complete"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer distribution:\n",
      "  Layer 0: 4 heads\n",
      "  Layer 1: 1 heads\n",
      "  Layer 3: 2 heads\n",
      "  Layer 6: 1 heads\n",
      "  Layer 7: 2 heads\n",
      "  Layer 8: 5 heads\n",
      "  Layer 9: 6 heads\n",
      "  Layer 10: 7 heads\n",
      "  Layer 11: 3 heads\n",
      "\n",
      "Layer with most heads: Layer 10 (7 heads)\n",
      "\n",
      "Early layers (0-3): 7 heads\n",
      "Late layers (9-11): 16 heads\n",
      "Trend: More heads in later layers\n"
     ]
    }
   ],
   "source": [
    "# Analyze the layer distribution of attention heads in the circuit\n",
    "# The circuit contains these attention heads (from the documentation):\n",
    "circuit_heads = [\n",
    "    \"a0.h1\", \"a0.h10\", \"a0.h5\", \"a0.h6\",\n",
    "    \"a1.h11\",\n",
    "    \"a3.h0\", \"a3.h6\",\n",
    "    \"a6.h0\",\n",
    "    \"a7.h3\", \"a7.h9\",\n",
    "    \"a8.h10\", \"a8.h2\", \"a8.h3\", \"a8.h5\", \"a8.h6\",\n",
    "    \"a9.h0\", \"a9.h2\", \"a9.h6\", \"a9.h7\", \"a9.h8\", \"a9.h9\",\n",
    "    \"a10.h0\", \"a10.h1\", \"a10.h10\", \"a10.h2\", \"a10.h3\", \"a10.h6\", \"a10.h7\",\n",
    "    \"a11.h10\", \"a11.h6\", \"a11.h8\"\n",
    "]\n",
    "\n",
    "# Count heads per layer\n",
    "layer_counts = {}\n",
    "for head in circuit_heads:\n",
    "    # Extract layer number from head name (e.g., \"a0.h1\" -> layer 0)\n",
    "    layer = int(head.split('.')[0][1:])  # Remove 'a' prefix and extract number\n",
    "    if layer not in layer_counts:\n",
    "        layer_counts[layer] = 0\n",
    "    layer_counts[layer] += 1\n",
    "\n",
    "# Find the layer with most heads\n",
    "max_layer = max(layer_counts, key=layer_counts.get)\n",
    "max_count = layer_counts[max_layer]\n",
    "\n",
    "# Calculate early vs late layer distribution\n",
    "# Early layers: 0-3, Late layers: 9-11\n",
    "early_layers_count = sum(layer_counts.get(layer, 0) for layer in range(0, 4))\n",
    "late_layers_count = sum(layer_counts.get(layer, 0) for layer in range(9, 12))\n",
    "\n",
    "# Print results\n",
    "print(\"Layer distribution:\")\n",
    "for layer in sorted(layer_counts.keys()):\n",
    "    print(f\"  Layer {layer}: {layer_counts[layer]} heads\")\n",
    "print(f\"\\nLayer with most heads: Layer {max_layer} ({max_count} heads)\")\n",
    "print(f\"\\nEarly layers (0-3): {early_layers_count} heads\")\n",
    "print(f\"Late layers (9-11): {late_layers_count} heads\")\n",
    "print(f\"Trend: {'More heads in later layers' if late_layers_count > early_layers_count else 'More heads in early layers'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e0b33a",
   "metadata": {},
   "source": [
    "**Reasoning:**\n",
    "The code extracts layer numbers from the attention head names (format: \"aX.hY\" where X is the layer) and counts the distribution. The documentation in Section 4 lists the layer distribution:\n",
    "- Layer 0: 4 heads\n",
    "- Layer 1: 1 head\n",
    "- Layer 3: 2 heads\n",
    "- Layer 6: 1 head\n",
    "- Layer 7: 2 heads\n",
    "- Layer 8: 5 heads\n",
    "- Layer 9: 5 heads (Note: my count shows 6 heads for layer 9)\n",
    "- Layer 10: 7 heads\n",
    "- Layer 11: 4 heads (Note: my count shows 3 heads for layer 11)\n",
    "\n",
    "The analysis shows Layer 10 has the most heads (7 heads). When comparing early layers (0-3) with 7 total heads versus late layers (9-11) with 16 total heads, there is a clear trend toward more heads in later layers. This aligns with the documentation's observation about \"layered processing\" where late layers (9-11) are responsible for \"Name moving and prediction\" which is the final and most critical step in the IOI task.\n",
    "\n",
    "**Answer:** Layer 10 has the most heads (7 heads). There is a clear trend showing more heads in later layers, with 16 heads in layers 9-11 compared to only 7 heads in layers 0-3. This supports the hypothesis that later layers perform the critical name-moving and prediction functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ea004d",
   "metadata": {},
   "source": [
    "### Question 17 (CQ3): Minimal Circuit Budget Calculation\n",
    "\n",
    "**Question:** Write code to simulate what would happen if you wanted to create a minimal IOI circuit using only the top-1 head from each functional category (Duplicate Token: a3.h0, S-Inhibition: a8.h6, Name-Mover: a9.h9) plus all 12 MLPs. Calculate the total budget used and how much budget remains unused compared to the full circuit.\n",
    "\n",
    "**Reference:** Section 3.3 (Circuit Node Selection) and Section 4 (Budget Verification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f62c1d64",
   "metadata": {
    "execution_status": "complete"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimal Circuit Composition:\n",
      "  - Attention heads: 3 heads × 64 dims = 192 dims\n",
      "  - MLPs: 12 MLPs × 768 dims = 9216 dims\n",
      "\n",
      "Minimal circuit budget: 9408 dimensions\n",
      "Budget remaining: 1792 dimensions\n",
      "Budget saved vs full circuit: 1792 dimensions\n",
      "\n",
      "Budget constraint (≤11,200): PASS\n"
     ]
    }
   ],
   "source": [
    "# Calculate budget for a minimal IOI circuit\n",
    "# Minimal circuit composition:\n",
    "# - Top Duplicate Token Head: a3.h0\n",
    "# - Top S-Inhibition Head: a8.h6\n",
    "# - Top Name-Mover Head: a9.h9\n",
    "# - All 12 MLPs (m0 through m11)\n",
    "\n",
    "# Constants\n",
    "DIMS_PER_HEAD = 64\n",
    "DIMS_PER_MLP = 768\n",
    "BUDGET_LIMIT = 11200\n",
    "FULL_CIRCUIT_BUDGET = 11200  # From the documentation\n",
    "\n",
    "# Calculate minimal circuit budget\n",
    "minimal_heads = 3  # One from each category\n",
    "minimal_mlps = 12\n",
    "minimal_budget = (minimal_heads * DIMS_PER_HEAD) + (minimal_mlps * DIMS_PER_MLP)\n",
    "\n",
    "# Calculate remaining budget\n",
    "budget_remaining = BUDGET_LIMIT - minimal_budget\n",
    "\n",
    "# Calculate savings compared to full circuit\n",
    "budget_saved = FULL_CIRCUIT_BUDGET - minimal_budget\n",
    "\n",
    "# Print results\n",
    "print(f\"Minimal Circuit Composition:\")\n",
    "print(f\"  - Attention heads: {minimal_heads} heads × {DIMS_PER_HEAD} dims = {minimal_heads * DIMS_PER_HEAD} dims\")\n",
    "print(f\"  - MLPs: {minimal_mlps} MLPs × {DIMS_PER_MLP} dims = {minimal_mlps * DIMS_PER_MLP} dims\")\n",
    "print(f\"\\nMinimal circuit budget: {minimal_budget} dimensions\")\n",
    "print(f\"Budget remaining: {budget_remaining} dimensions\")\n",
    "print(f\"Budget saved vs full circuit: {budget_saved} dimensions\")\n",
    "print(f\"\\nBudget constraint (≤11,200): {'PASS' if minimal_budget <= BUDGET_LIMIT else 'FAIL'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b220dd8",
   "metadata": {},
   "source": [
    "**Reasoning:**\n",
    "The minimal circuit uses only the top-performing head from each of the three functional categories identified in the documentation (Section 3.3 Step 2):\n",
    "- **Duplicate Token Head**: a3.h0 (highest S2→S1 attention at 0.7191)\n",
    "- **S-Inhibition Head**: a8.h6 (highest END→S2 attention at 0.7441)\n",
    "- **Name-Mover Head**: a9.h9 (highest END→IO attention at 0.7998)\n",
    "\n",
    "Plus all 12 MLPs (as the documentation states they are important for \"feature extraction and transformation\").\n",
    "\n",
    "The calculation:\n",
    "- 3 heads × 64 dims = 192 dimensions\n",
    "- 12 MLPs × 768 dims = 9,216 dimensions\n",
    "- Total = 9,408 dimensions\n",
    "\n",
    "This is 1,792 dimensions less than the full circuit (11,200 dims), saving 16% of the budget. The minimal circuit still passes the budget constraint and represents a highly efficient hypothesis-driven design focusing on one representative from each functional category.\n",
    "\n",
    "**Answer:** A minimal IOI circuit using only the top-1 head from each functional category plus all MLPs would use 9,408 dimensions, leaving 1,792 dimensions of unused budget. This saves 1,792 dimensions compared to the full circuit while still maintaining coverage of all three hypothesized functional components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc3e9299",
   "metadata": {
    "execution_status": "pending"
   },
   "outputs": [],
   "source": [
    "# Save the notebook to the exam directory\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "# Current notebook path\n",
    "current_notebook = \"/home/smallyan/critic_model_mechinterp/notebooks/2025-11-14-11-41_ExamAnswers.ipynb\"\n",
    "\n",
    "# Target directory and filename\n",
    "target_dir = \"/home/smallyan/critic_model_mechinterp/runs/circuits_claude_2025-11-09_14-46-37/exam\"\n",
    "target_file = os.path.join(target_dir, \"student_answer.ipynb\")\n",
    "\n",
    "# Ensure the target directory exists\n",
    "os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "# Copy the notebook to the target location\n",
    "shutil.copy2(current_notebook, target_file)\n",
    "\n",
    "print(f\"Notebook saved successfully!\")\n",
    "print(f\"Source: {current_notebook}\")\n",
    "print(f\"Destination: {target_file}\")\n",
    "print(f\"\\nVerifying file exists: {os.path.exists(target_file)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scribe: 2025-11-14-11-41_ExamAnswers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
