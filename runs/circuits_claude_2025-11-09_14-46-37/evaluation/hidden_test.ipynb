{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55f6b67b",
   "metadata": {},
   "source": [
    "# Hidden Test: Circuit Function Validation\n",
    "\n",
    "This notebook tests whether each neuron/head in the student's identified circuit matches its hypothesized function as described in the instructor's plan.\n",
    "\n",
    "## Test Goals\n",
    "\n",
    "1. Load the student's identified circuit\n",
    "2. Load GPT2-small and IOI dataset\n",
    "3. For each head category, verify it performs its hypothesized function:\n",
    "   - **Duplicate Token Heads**: Should attend from S2 to S1\n",
    "   - **S-Inhibition Heads**: Should attend from END to S2\n",
    "   - **Name-Mover Heads**: Should attend from END to IO\n",
    "4. Provide quantitative metrics for each head's performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36883cec",
   "metadata": {
    "execution_status": "complete"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU: NVIDIA A40\n",
      "\n",
      "Loaded circuit with 44 nodes\n",
      "Attention heads: 31\n",
      "MLPs: 12\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import json\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Set working directory\n",
    "os.chdir('/home/smallyan/critic_model_mechinterp')\n",
    "\n",
    "# Check GPU\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "# Load the student's circuit\n",
    "circuit_path = 'runs/circuits_claude_2025-11-09_14-46-37/results/real_circuits_1.json'\n",
    "with open(circuit_path, 'r') as f:\n",
    "    circuit = json.load(f)\n",
    "\n",
    "print(f\"\\nLoaded circuit with {len(circuit['nodes'])} nodes\")\n",
    "print(f\"Attention heads: {len([n for n in circuit['nodes'] if n.startswith('a')])}\")\n",
    "print(f\"MLPs: {len([n for n in circuit['nodes'] if n.startswith('m')])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7313e193",
   "metadata": {
    "execution_status": "complete"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading TransformerLens and datasets...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Libraries loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# Install and import necessary libraries\n",
    "print(\"Loading TransformerLens and datasets...\")\n",
    "\n",
    "try:\n",
    "    from transformer_lens import HookedTransformer\n",
    "    from datasets import load_dataset\n",
    "    print(\"✓ Libraries loaded successfully\")\n",
    "except ImportError as e:\n",
    "    print(f\"Error importing libraries: {e}\")\n",
    "    print(\"Attempting to install...\")\n",
    "    import subprocess\n",
    "    subprocess.run([\"pip\", \"install\", \"-q\", \"transformer-lens\", \"datasets\"], check=True)\n",
    "    from transformer_lens import HookedTransformer\n",
    "    from datasets import load_dataset\n",
    "    print(\"✓ Libraries installed and loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6e69be8",
   "metadata": {
    "execution_status": "complete"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading GPT2-small model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n",
      "✓ Model loaded: 12 layers, 12 heads per layer\n",
      "  d_model: 768, d_head: 64\n",
      "\n",
      "Loading IOI dataset...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Dataset loaded: 10000 examples\n",
      "Using 50 examples for hidden testing\n"
     ]
    }
   ],
   "source": [
    "# Load GPT2-small model\n",
    "print(\"Loading GPT2-small model...\")\n",
    "model = HookedTransformer.from_pretrained(\"gpt2-small\", device=device)\n",
    "print(f\"✓ Model loaded: {model.cfg.n_layers} layers, {model.cfg.n_heads} heads per layer\")\n",
    "print(f\"  d_model: {model.cfg.d_model}, d_head: {model.cfg.d_head}\")\n",
    "\n",
    "# Load IOI dataset - trying correct name\n",
    "print(\"\\nLoading IOI dataset...\")\n",
    "try:\n",
    "    # Try mib-bench/ioi as specified in instructor's prompt\n",
    "    dataset = load_dataset(\"mib-bench/ioi\", split=\"train\")\n",
    "except Exception as e:\n",
    "    print(f\"Trying alternative dataset name: {e}\")\n",
    "    # Alternative: load from canonical source\n",
    "    dataset = load_dataset(\"Eleuther/ioi\", split=\"train\")\n",
    "    \n",
    "print(f\"✓ Dataset loaded: {len(dataset)} examples\")\n",
    "\n",
    "# Use first 50 examples for testing (different from student's 100)\n",
    "test_size = 50\n",
    "test_dataset = dataset.select(range(test_size))\n",
    "print(f\"Using {test_size} examples for hidden testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5649bc0a",
   "metadata": {
    "execution_status": "complete"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset structure:\n",
      "{'template': 'As {name_A} and {name_B} left the {place}, {name_C} gave a {object} to', 'metadata': {'indirect_object': 'Maria', 'object': 'fridge', 'place': 'consulate', 'random_a': 'Bob', 'random_b': 'Max', 'random_c': 'Gene', 'subject': 'Carl'}, 'prompt': 'As Carl and Maria left the consulate, Carl gave a fridge to', 'choices': ['Maria', 'Carl'], 'answerKey': 0, 'abc_counterfactual': {'answerKey': -1, 'choices': ['Maria', 'Carl', 'Gene'], 'prompt': 'As Carl and Maria left the consulate, Gene gave a fridge to'}, 'random_names_counterfactual': {'answerKey': 1, 'choices': ['Bob', 'Max'], 'prompt': 'As Bob and Max left the consulate, Bob gave a fridge to'}, 's1_io_flip_counterfactual': {'answerKey': 0, 'choices': ['Maria', 'Carl'], 'prompt': 'As Maria and Carl left the consulate, Carl gave a fridge to'}, 's2_io_flip_counterfactual': {'answerKey': 1, 'choices': ['Maria', 'Carl'], 'prompt': 'As Carl and Maria left the consulate, Maria gave a fridge to'}, 'random_names_s1_ioi_flip_counterfactual': {'answerKey': 1, 'choices': ['Bob', 'Max'], 'prompt': 'As Max and Bob left the consulate, Bob gave a fridge to'}, 'random_names_s2_ioi_flip_counterfactual': {'answerKey': 0, 'choices': ['Bob', 'Max'], 'prompt': 'As Bob and Max left the consulate, Max gave a fridge to'}, 's1_ioi_flip_s2_ioi_flip_counterfactual': {'answerKey': 1, 'choices': ['Maria', 'Carl'], 'prompt': 'As Maria and Carl left the consulate, Maria gave a fridge to'}, 'random_names_s1_ioi_flip_s2_ioi_flip_counterfactual': {'answerKey': 0, 'choices': ['Bob', 'Max'], 'prompt': 'As Max and Bob left the consulate, Max gave a fridge to'}}\n",
      "\n",
      "Dataset features: {'template': Value('string'), 'metadata': {'indirect_object': Value('string'), 'object': Value('string'), 'place': Value('string'), 'random_a': Value('string'), 'random_b': Value('string'), 'random_c': Value('string'), 'subject': Value('string')}, 'prompt': Value('string'), 'choices': List(Value('string')), 'answerKey': Value('int64'), 'abc_counterfactual': {'answerKey': Value('int64'), 'choices': List(Value('string')), 'prompt': Value('string')}, 'random_names_counterfactual': {'answerKey': Value('int64'), 'choices': List(Value('string')), 'prompt': Value('string')}, 's1_io_flip_counterfactual': {'answerKey': Value('int64'), 'choices': List(Value('string')), 'prompt': Value('string')}, 's2_io_flip_counterfactual': {'answerKey': Value('int64'), 'choices': List(Value('string')), 'prompt': Value('string')}, 'random_names_s1_ioi_flip_counterfactual': {'answerKey': Value('int64'), 'choices': List(Value('string')), 'prompt': Value('string')}, 'random_names_s2_ioi_flip_counterfactual': {'answerKey': Value('int64'), 'choices': List(Value('string')), 'prompt': Value('string')}, 's1_ioi_flip_s2_ioi_flip_counterfactual': {'answerKey': Value('int64'), 'choices': List(Value('string')), 'prompt': Value('string')}, 'random_names_s1_ioi_flip_s2_ioi_flip_counterfactual': {'answerKey': Value('int64'), 'choices': List(Value('string')), 'prompt': Value('string')}}\n"
     ]
    }
   ],
   "source": [
    "# Examine the dataset structure\n",
    "print(\"Dataset structure:\")\n",
    "print(test_dataset[0])\n",
    "print(\"\\nDataset features:\", test_dataset.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "679adb16",
   "metadata": {
    "execution_status": "complete"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example prompt: As Carl and Maria left the consulate, Carl gave a fridge to\n",
      "Subject: Carl\n",
      "IO: Maria\n",
      "\n",
      "Token positions:\n",
      "  S1 (first subject): position 2 = ' Carl'\n",
      "  IO: position 4 = ' Maria'\n",
      "  S2 (second subject): position 9 = ' Carl'\n",
      "  END: position 13 = ' to'\n",
      "\n",
      "All tokens: ['<|endoftext|>', 'As', ' Carl', ' and', ' Maria', ' left', ' the', ' consulate', ',', ' Carl', ' gave', ' a', ' fridge', ' to']\n"
     ]
    }
   ],
   "source": [
    "# Helper function to identify key token positions in IOI prompts\n",
    "def get_token_positions(prompt_text, subject, io):\n",
    "    \"\"\"\n",
    "    Identify positions of S1, S2, IO, and END tokens\n",
    "    Example: \"As Carl and Maria left the consulate, Carl gave a fridge to\"\n",
    "    S1 = first \"Carl\", IO = \"Maria\", S2 = second \"Carl\", END = \"to\"\n",
    "    \"\"\"\n",
    "    tokens = model.to_tokens(prompt_text, prepend_bos=True)\n",
    "    tokens_str = model.to_str_tokens(prompt_text, prepend_bos=True)\n",
    "    \n",
    "    # Find subject and IO token positions\n",
    "    subject_positions = []\n",
    "    io_positions = []\n",
    "    \n",
    "    for i, tok in enumerate(tokens_str):\n",
    "        if subject.lower() in tok.lower():\n",
    "            subject_positions.append(i)\n",
    "        if io.lower() in tok.lower():\n",
    "            io_positions.append(i)\n",
    "    \n",
    "    # S1 is first subject mention, S2 is second subject mention\n",
    "    s1_pos = subject_positions[0] if len(subject_positions) > 0 else None\n",
    "    s2_pos = subject_positions[1] if len(subject_positions) > 1 else None\n",
    "    io_pos = io_positions[0] if len(io_positions) > 0 else None\n",
    "    end_pos = len(tokens_str) - 1  # Last token position\n",
    "    \n",
    "    return {\n",
    "        's1': s1_pos,\n",
    "        's2': s2_pos,\n",
    "        'io': io_pos,\n",
    "        'end': end_pos,\n",
    "        'tokens': tokens,\n",
    "        'tokens_str': tokens_str\n",
    "    }\n",
    "\n",
    "# Test on first example\n",
    "example = test_dataset[0]\n",
    "positions = get_token_positions(\n",
    "    example['prompt'], \n",
    "    example['metadata']['subject'],\n",
    "    example['metadata']['indirect_object']\n",
    ")\n",
    "\n",
    "print(\"Example prompt:\", example['prompt'])\n",
    "print(f\"Subject: {example['metadata']['subject']}\")\n",
    "print(f\"IO: {example['metadata']['indirect_object']}\")\n",
    "print(\"\\nToken positions:\")\n",
    "print(f\"  S1 (first subject): position {positions['s1']} = '{positions['tokens_str'][positions['s1']]}'\")\n",
    "print(f\"  IO: position {positions['io']} = '{positions['tokens_str'][positions['io']]}'\")\n",
    "print(f\"  S2 (second subject): position {positions['s2']} = '{positions['tokens_str'][positions['s2']]}'\")\n",
    "print(f\"  END: position {positions['end']} = '{positions['tokens_str'][positions['end']]}'\")\n",
    "print(f\"\\nAll tokens: {positions['tokens_str']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d8eca3",
   "metadata": {},
   "source": [
    "## Test 1: Duplicate Token Heads (S2 → S1 Attention)\n",
    "\n",
    "Testing whether the identified duplicate token heads actually attend from S2 to S1 as hypothesized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66a03f7d",
   "metadata": {
    "execution_status": "complete"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Duplicate Token Heads (S2 → S1 attention)\n",
      "======================================================================\n",
      "Testing 6 heads identified by student\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      "\n",
      "a0.h1: 0.5171 ± 0.0331  ✓ PASS\n",
      "a0.h5: 0.6064 ± 0.0459  ✓ PASS\n",
      "a0.h10: 0.2378 ± 0.0235  ⚠ WEAK\n",
      "a1.h11: 0.6511 ± 0.0816  ✓ PASS\n",
      "a3.h0: 0.7024 ± 0.1097  ✓ PASS\n",
      "a3.h6: 0.0111 ± 0.0061  ✗ FAIL\n",
      "\n",
      "======================================================================\n",
      "Pass rate: 66.7% (4/6 heads)\n",
      "Overall: ✓ PASS\n"
     ]
    }
   ],
   "source": [
    "# Extract the duplicate token heads from student's circuit\n",
    "# According to student's documentation, these are the duplicate token heads:\n",
    "duplicate_token_heads = [\n",
    "    'a0.h1', 'a0.h5', 'a0.h10', 'a1.h11', 'a3.h0', 'a3.h6'\n",
    "]\n",
    "\n",
    "print(\"Testing Duplicate Token Heads (S2 → S1 attention)\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Testing {len(duplicate_token_heads)} heads identified by student\\n\")\n",
    "\n",
    "# Collect attention patterns across test examples\n",
    "attention_scores = {head: [] for head in duplicate_token_heads}\n",
    "\n",
    "for i, example in enumerate(test_dataset):\n",
    "    prompt = example['prompt']\n",
    "    subject = example['metadata']['subject']\n",
    "    io = example['metadata']['indirect_object']\n",
    "    \n",
    "    # Get positions\n",
    "    pos = get_token_positions(prompt, subject, io)\n",
    "    \n",
    "    if pos['s1'] is None or pos['s2'] is None:\n",
    "        continue\n",
    "    \n",
    "    # Run model with cache\n",
    "    tokens = pos['tokens']\n",
    "    logits, cache = model.run_with_cache(tokens)\n",
    "    \n",
    "    # Check attention for each head\n",
    "    for head_name in duplicate_token_heads:\n",
    "        # Parse head name: a{layer}.h{head}\n",
    "        layer = int(head_name.split('.')[0][1:])\n",
    "        head = int(head_name.split('.')[1][1:])\n",
    "        \n",
    "        # Get attention pattern: [batch, head, query_pos, key_pos]\n",
    "        attn_pattern = cache['pattern', layer][0, head]\n",
    "        \n",
    "        # Get attention from S2 to S1\n",
    "        s2_to_s1_attn = attn_pattern[pos['s2'], pos['s1']].item()\n",
    "        attention_scores[head_name].append(s2_to_s1_attn)\n",
    "\n",
    "# Calculate statistics\n",
    "print(\"Results:\\n\")\n",
    "results_dup = []\n",
    "for head_name in duplicate_token_heads:\n",
    "    scores = attention_scores[head_name]\n",
    "    mean_score = np.mean(scores)\n",
    "    std_score = np.std(scores)\n",
    "    \n",
    "    # Threshold: consider \"strong\" if mean > 0.3\n",
    "    status = \"✓ PASS\" if mean_score > 0.3 else \"⚠ WEAK\" if mean_score > 0.15 else \"✗ FAIL\"\n",
    "    \n",
    "    print(f\"{head_name}: {mean_score:.4f} ± {std_score:.4f}  {status}\")\n",
    "    results_dup.append({\n",
    "        'head': head_name,\n",
    "        'mean': mean_score,\n",
    "        'std': std_score,\n",
    "        'pass': mean_score > 0.3\n",
    "    })\n",
    "\n",
    "pass_rate = sum(1 for r in results_dup if r['pass']) / len(results_dup)\n",
    "print(f\"\\n{'=' * 70}\")\n",
    "print(f\"Pass rate: {pass_rate:.1%} ({sum(1 for r in results_dup if r['pass'])}/{len(results_dup)} heads)\")\n",
    "print(f\"Overall: {'✓ PASS' if pass_rate >= 0.5 else '✗ FAIL'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9cbada",
   "metadata": {},
   "source": [
    "## Test 2: S-Inhibition Heads (END → S2 Attention)\n",
    "\n",
    "Testing whether the identified S-inhibition heads attend from END to S2 as hypothesized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c023cd16",
   "metadata": {
    "execution_status": "complete"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing S-Inhibition Heads (END → S2 attention)\n",
      "======================================================================\n",
      "Testing 12 heads identified by student\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      "\n",
      "a7.h3: 0.1545 ± 0.0798  ⚠ WEAK\n",
      "a7.h9: 0.4982 ± 0.1904  ✓ PASS\n",
      "a8.h2: 0.0973 ± 0.0524  ✗ FAIL\n",
      "a8.h3: 0.0239 ± 0.0202  ✗ FAIL\n",
      "a8.h5: 0.2846 ± 0.1254  ✓ PASS\n",
      "a8.h6: 0.7311 ± 0.2438  ✓ PASS\n",
      "a8.h10: 0.2955 ± 0.1403  ✓ PASS\n",
      "a9.h0: 0.0159 ± 0.0096  ✗ FAIL\n",
      "a9.h2: 0.0284 ± 0.0209  ✗ FAIL\n",
      "a9.h7: 0.2574 ± 0.1052  ✓ PASS\n",
      "a9.h8: 0.0519 ± 0.0402  ✗ FAIL\n",
      "a11.h6: 0.0340 ± 0.0238  ✗ FAIL\n",
      "\n",
      "======================================================================\n",
      "Pass rate: 41.7% (5/12 heads)\n",
      "Overall: ✗ FAIL\n"
     ]
    }
   ],
   "source": [
    "# Extract the S-inhibition heads from student's circuit\n",
    "s_inhibition_heads = [\n",
    "    'a7.h3', 'a7.h9', 'a8.h2', 'a8.h3', 'a8.h5', 'a8.h6', \n",
    "    'a8.h10', 'a9.h0', 'a9.h2', 'a9.h7', 'a9.h8', 'a11.h6'\n",
    "]\n",
    "\n",
    "print(\"Testing S-Inhibition Heads (END → S2 attention)\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Testing {len(s_inhibition_heads)} heads identified by student\\n\")\n",
    "\n",
    "# Collect attention patterns\n",
    "attention_scores_sinh = {head: [] for head in s_inhibition_heads}\n",
    "\n",
    "for i, example in enumerate(test_dataset):\n",
    "    prompt = example['prompt']\n",
    "    subject = example['metadata']['subject']\n",
    "    io = example['metadata']['indirect_object']\n",
    "    \n",
    "    # Get positions\n",
    "    pos = get_token_positions(prompt, subject, io)\n",
    "    \n",
    "    if pos['s2'] is None or pos['end'] is None:\n",
    "        continue\n",
    "    \n",
    "    # Run model with cache\n",
    "    tokens = pos['tokens']\n",
    "    logits, cache = model.run_with_cache(tokens)\n",
    "    \n",
    "    # Check attention for each head\n",
    "    for head_name in s_inhibition_heads:\n",
    "        layer = int(head_name.split('.')[0][1:])\n",
    "        head = int(head_name.split('.')[1][1:])\n",
    "        \n",
    "        attn_pattern = cache['pattern', layer][0, head]\n",
    "        \n",
    "        # Get attention from END to S2\n",
    "        end_to_s2_attn = attn_pattern[pos['end'], pos['s2']].item()\n",
    "        attention_scores_sinh[head_name].append(end_to_s2_attn)\n",
    "\n",
    "# Calculate statistics\n",
    "print(\"Results:\\n\")\n",
    "results_sinh = []\n",
    "for head_name in s_inhibition_heads:\n",
    "    scores = attention_scores_sinh[head_name]\n",
    "    mean_score = np.mean(scores)\n",
    "    std_score = np.std(scores)\n",
    "    \n",
    "    status = \"✓ PASS\" if mean_score > 0.2 else \"⚠ WEAK\" if mean_score > 0.1 else \"✗ FAIL\"\n",
    "    \n",
    "    print(f\"{head_name}: {mean_score:.4f} ± {std_score:.4f}  {status}\")\n",
    "    results_sinh.append({\n",
    "        'head': head_name,\n",
    "        'mean': mean_score,\n",
    "        'std': std_score,\n",
    "        'pass': mean_score > 0.2\n",
    "    })\n",
    "\n",
    "pass_rate = sum(1 for r in results_sinh if r['pass']) / len(results_sinh)\n",
    "print(f\"\\n{'=' * 70}\")\n",
    "print(f\"Pass rate: {pass_rate:.1%} ({sum(1 for r in results_sinh if r['pass'])}/{len(results_sinh)} heads)\")\n",
    "print(f\"Overall: {'✓ PASS' if pass_rate >= 0.5 else '✗ FAIL'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c4bb81",
   "metadata": {},
   "source": [
    "## Test 3: Name-Mover Heads (END → IO Attention)\n",
    "\n",
    "Testing whether the identified name-mover heads attend from END to IO as hypothesized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41b667e5",
   "metadata": {
    "execution_status": "complete"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Name-Mover Heads (END → IO attention)\n",
      "======================================================================\n",
      "Testing 13 heads identified by student\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      "\n",
      "a0.h6: 0.0374 ± 0.0149  ✗ FAIL\n",
      "a6.h0: 0.0067 ± 0.0047  ✗ FAIL\n",
      "a9.h6: 0.7181 ± 0.2424  ✓ PASS\n",
      "a9.h9: 0.7788 ± 0.2562  ✓ PASS\n",
      "a10.h0: 0.3855 ± 0.1809  ✓ PASS\n",
      "a10.h1: 0.3324 ± 0.1829  ✓ PASS\n",
      "a10.h2: 0.2074 ± 0.1485  ⚠ WEAK\n",
      "a10.h3: 0.2245 ± 0.2207  ⚠ WEAK\n",
      "a10.h6: 0.2867 ± 0.1773  ⚠ WEAK\n",
      "a10.h7: 0.7611 ± 0.2583  ✓ PASS\n",
      "a10.h10: 0.3456 ± 0.1510  ✓ PASS\n",
      "a11.h8: 0.0117 ± 0.0095  ✗ FAIL\n",
      "a11.h10: 0.6296 ± 0.2239  ✓ PASS\n",
      "\n",
      "======================================================================\n",
      "Pass rate: 53.8% (7/13 heads)\n",
      "Overall: ✓ PASS\n"
     ]
    }
   ],
   "source": [
    "# Extract the name-mover heads from student's circuit\n",
    "name_mover_heads = [\n",
    "    'a0.h6', 'a6.h0', 'a9.h6', 'a9.h9', 'a10.h0', 'a10.h1', \n",
    "    'a10.h2', 'a10.h3', 'a10.h6', 'a10.h7', 'a10.h10', \n",
    "    'a11.h8', 'a11.h10'\n",
    "]\n",
    "\n",
    "print(\"Testing Name-Mover Heads (END → IO attention)\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Testing {len(name_mover_heads)} heads identified by student\\n\")\n",
    "\n",
    "# Collect attention patterns\n",
    "attention_scores_nm = {head: [] for head in name_mover_heads}\n",
    "\n",
    "for i, example in enumerate(test_dataset):\n",
    "    prompt = example['prompt']\n",
    "    subject = example['metadata']['subject']\n",
    "    io = example['metadata']['indirect_object']\n",
    "    \n",
    "    # Get positions\n",
    "    pos = get_token_positions(prompt, subject, io)\n",
    "    \n",
    "    if pos['io'] is None or pos['end'] is None:\n",
    "        continue\n",
    "    \n",
    "    # Run model with cache\n",
    "    tokens = pos['tokens']\n",
    "    logits, cache = model.run_with_cache(tokens)\n",
    "    \n",
    "    # Check attention for each head\n",
    "    for head_name in name_mover_heads:\n",
    "        layer = int(head_name.split('.')[0][1:])\n",
    "        head = int(head_name.split('.')[1][1:])\n",
    "        \n",
    "        attn_pattern = cache['pattern', layer][0, head]\n",
    "        \n",
    "        # Get attention from END to IO\n",
    "        end_to_io_attn = attn_pattern[pos['end'], pos['io']].item()\n",
    "        attention_scores_nm[head_name].append(end_to_io_attn)\n",
    "\n",
    "# Calculate statistics\n",
    "print(\"Results:\\n\")\n",
    "results_nm = []\n",
    "for head_name in name_mover_heads:\n",
    "    scores = attention_scores_nm[head_name]\n",
    "    mean_score = np.mean(scores)\n",
    "    std_score = np.std(scores)\n",
    "    \n",
    "    status = \"✓ PASS\" if mean_score > 0.3 else \"⚠ WEAK\" if mean_score > 0.15 else \"✗ FAIL\"\n",
    "    \n",
    "    print(f\"{head_name}: {mean_score:.4f} ± {std_score:.4f}  {status}\")\n",
    "    results_nm.append({\n",
    "        'head': head_name,\n",
    "        'mean': mean_score,\n",
    "        'std': std_score,\n",
    "        'pass': mean_score > 0.3\n",
    "    })\n",
    "\n",
    "pass_rate = sum(1 for r in results_nm if r['pass']) / len(results_nm)\n",
    "print(f\"\\n{'=' * 70}\")\n",
    "print(f\"Pass rate: {pass_rate:.1%} ({sum(1 for r in results_nm if r['pass'])}/{len(results_nm)} heads)\")\n",
    "print(f\"Overall: {'✓ PASS' if pass_rate >= 0.5 else '✗ FAIL'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771138c1",
   "metadata": {},
   "source": [
    "## Summary of Hidden Tests\n",
    "\n",
    "### Overall Circuit Function Validation\n",
    "\n",
    "Testing whether the student's identified circuit nodes match their hypothesized functions using 50 independent test examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0321b688",
   "metadata": {
    "execution_status": "complete"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "HIDDEN TEST RESULTS SUMMARY\n",
      "================================================================================\n",
      "\n",
      "### Test Results by Category:\n",
      "\n",
      "Duplicate Token Heads (S2→S1)\n",
      "  Heads tested: 6\n",
      "  Heads passed: 4\n",
      "  Pass rate: 66.7%\n",
      "  Status: ✓ PASS\n",
      "\n",
      "S-Inhibition Heads (END→S2)\n",
      "  Heads tested: 12\n",
      "  Heads passed: 5\n",
      "  Pass rate: 41.7%\n",
      "  Status: ✗ FAIL\n",
      "\n",
      "Name-Mover Heads (END→IO)\n",
      "  Heads tested: 13\n",
      "  Heads passed: 7\n",
      "  Pass rate: 53.8%\n",
      "  Status: ✓ PASS\n",
      "\n",
      "================================================================================\n",
      "OVERALL CIRCUIT VALIDATION:\n",
      "  Total heads tested: 31\n",
      "  Total heads passed: 16\n",
      "  Overall pass rate: 51.6%\n",
      "  Status: ✓ PASS\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"HIDDEN TEST RESULTS SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Compile all results\n",
    "all_results = {\n",
    "    \"Duplicate Token Heads (S2→S1)\": {\n",
    "        \"tested\": len(results_dup),\n",
    "        \"passed\": sum(1 for r in results_dup if r['pass']),\n",
    "        \"pass_rate\": sum(1 for r in results_dup if r['pass']) / len(results_dup),\n",
    "        \"overall\": \"✓ PASS\" if sum(1 for r in results_dup if r['pass']) / len(results_dup) >= 0.5 else \"✗ FAIL\"\n",
    "    },\n",
    "    \"S-Inhibition Heads (END→S2)\": {\n",
    "        \"tested\": len(results_sinh),\n",
    "        \"passed\": sum(1 for r in results_sinh if r['pass']),\n",
    "        \"pass_rate\": sum(1 for r in results_sinh if r['pass']) / len(results_sinh),\n",
    "        \"overall\": \"✓ PASS\" if sum(1 for r in results_sinh if r['pass']) / len(results_sinh) >= 0.5 else \"✗ FAIL\"\n",
    "    },\n",
    "    \"Name-Mover Heads (END→IO)\": {\n",
    "        \"tested\": len(results_nm),\n",
    "        \"passed\": sum(1 for r in results_nm if r['pass']),\n",
    "        \"pass_rate\": sum(1 for r in results_nm if r['pass']) / len(results_nm),\n",
    "        \"overall\": \"✓ PASS\" if sum(1 for r in results_nm if r['pass']) / len(results_nm) >= 0.5 else \"✗ FAIL\"\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"\\n### Test Results by Category:\\n\")\n",
    "for category, results in all_results.items():\n",
    "    print(f\"{category}\")\n",
    "    print(f\"  Heads tested: {results['tested']}\")\n",
    "    print(f\"  Heads passed: {results['passed']}\")\n",
    "    print(f\"  Pass rate: {results['pass_rate']:.1%}\")\n",
    "    print(f\"  Status: {results['overall']}\")\n",
    "    print()\n",
    "\n",
    "# Overall statistics\n",
    "total_heads = sum(r['tested'] for r in all_results.values())\n",
    "total_passed = sum(r['passed'] for r in all_results.values())\n",
    "overall_pass_rate = total_passed / total_heads\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(f\"OVERALL CIRCUIT VALIDATION:\")\n",
    "print(f\"  Total heads tested: {total_heads}\")\n",
    "print(f\"  Total heads passed: {total_passed}\")\n",
    "print(f\"  Overall pass rate: {overall_pass_rate:.1%}\")\n",
    "print(f\"  Status: {'✓ PASS' if overall_pass_rate >= 0.5 else '✗ FAIL'}\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96fbb6f",
   "metadata": {},
   "source": [
    "## Critical Analysis\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "1. **Duplicate Token Heads**: Strong performance (66.7% pass rate)\n",
    "   - Top performers: a3.h0 (0.70), a1.h11 (0.65), a0.h5 (0.61)\n",
    "   - Weak performer: a3.h6 (0.01) - likely misclassified\n",
    "\n",
    "2. **S-Inhibition Heads**: Weak performance (41.7% pass rate) ⚠️\n",
    "   - Top performers: a8.h6 (0.73), a7.h9 (0.50)\n",
    "   - Many heads show very low END→S2 attention\n",
    "   - This category needs refinement\n",
    "\n",
    "3. **Name-Mover Heads**: Good performance (53.8% pass rate)\n",
    "   - Top performers: a9.h9 (0.78), a9.h6 (0.72), a10.h7 (0.76)\n",
    "   - Several weak performers in early layers (a0.h6, a6.h0)\n",
    "\n",
    "### Issues Identified\n",
    "\n",
    "1. **Overfitting to training data**: Student used 100 examples, but several heads don't generalize to new test examples\n",
    "2. **Loose selection criteria**: Some heads were likely included to maximize budget usage rather than functional accuracy\n",
    "3. **S-Inhibition category**: Only 41.7% of identified heads actually perform the hypothesized function\n",
    "\n",
    "### Recommendations\n",
    "\n",
    "1. Use stricter attention thresholds (>0.4 instead of lower values)\n",
    "2. Perform cross-validation with held-out test sets\n",
    "3. Consider removing low-performing heads from the circuit\n",
    "4. Re-examine S-inhibition head selection methodology"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scribe: 2025-11-09-18-52_HiddenTestEvaluation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
