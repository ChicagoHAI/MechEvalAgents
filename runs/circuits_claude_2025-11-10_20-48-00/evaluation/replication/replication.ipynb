{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "594b0b59",
   "metadata": {
    "execution_status": "complete"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /home/smallyan/critic_model_mechinterp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "CUDA device: NVIDIA A100 80GB PCIe\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Set working directory\n",
    "os.chdir('/home/smallyan/critic_model_mechinterp')\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n",
    "\n",
    "# Check if CUDA is available\n",
    "import torch\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b0e0672",
   "metadata": {
    "execution_status": "complete"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repository found at: /home/smallyan/critic_model_mechinterp/runs/circuits_claude_2025-11-10_20-48-00\n",
      "\n",
      "Directory structure:\n",
      "circuits_claude_2025-11-10_20-48-00/\n",
      "  notebooks/\n",
      "    2025-11-10-20-48_SarcasmCircuitAnalysis.ipynb\n",
      "  evaluation/\n",
      "    matching_report.ipynb\n",
      "    CRITIC_EVALUATION_SUMMARY.md\n",
      "    eval_summary_ts.ipynb\n",
      "    evaluation_replication.md\n",
      "    self_matching.ipynb\n",
      "    hidden_test.ipynb\n",
      "    goal_matching.ipynb\n",
      "    eval_summary_self.ipynb\n",
      "    code_critic_evaluation.ipynb\n",
      "    README.md\n",
      "    comparison_metrics.json\n",
      "  logs/\n",
      "    documentation.md\n",
      "    code_walk.md\n",
      "    plan_v2.md\n",
      "    plan_v1.md\n",
      "    circuit_prompt_sarcarsm_claude.log\n",
      "  exam/\n",
      "  results/\n",
      "    circuit_visualization.png\n",
      "    real_circuits_1_reproduced.json\n",
      "    real_circuits_1.json\n"
     ]
    }
   ],
   "source": [
    "# Define the repo root\n",
    "REPO_ROOT = '/home/smallyan/critic_model_mechinterp/runs/circuits_claude_2025-11-10_20-48-00'\n",
    "\n",
    "# Check if repo exists and list contents\n",
    "if os.path.exists(REPO_ROOT):\n",
    "    print(f\"Repository found at: {REPO_ROOT}\")\n",
    "    print(\"\\nDirectory structure:\")\n",
    "    for root, dirs, files in os.walk(REPO_ROOT):\n",
    "        level = root.replace(REPO_ROOT, '').count(os.sep)\n",
    "        indent = ' ' * 2 * level\n",
    "        print(f'{indent}{os.path.basename(root)}/')\n",
    "        subindent = ' ' * 2 * (level + 1)\n",
    "        for file in files:\n",
    "            print(f'{subindent}{file}')\n",
    "else:\n",
    "    print(f\"Repository not found at: {REPO_ROOT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d988417",
   "metadata": {},
   "source": [
    "# Sarcasm Circuit Analysis - Independent Replication\n",
    "\n",
    "## Goal\n",
    "Replicate the experiment described in the plan and code walk documents to identify the sarcasm detection circuit in GPT2-small using differential activation analysis.\n",
    "\n",
    "## Approach\n",
    "1. Load GPT2-small model\n",
    "2. Create paired sarcastic/literal text examples\n",
    "3. Run both through the model and collect activations\n",
    "4. Measure differential activation across all components\n",
    "5. Select components based on budget constraints (11,200 dimensions)\n",
    "6. Output circuit as JSON\n",
    "\n",
    "## Expected Result\n",
    "A 54-component circuit including:\n",
    "- Input embedding (768 dims)\n",
    "- 10 MLP layers (7,680 dims)\n",
    "- 43 attention heads (2,752 dims)\n",
    "\n",
    "Key finding: Layer 2 MLP (m2) should show dominant differential activation (~32.47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8542f877",
   "metadata": {
    "execution_status": "complete"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loading GPT2-small model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n",
      "\n",
      "Model configuration:\n",
      "  n_layers: 12\n",
      "  n_heads: 12\n",
      "  d_model: 768\n",
      "  d_head: 64\n",
      "\n",
      "Budget constraints:\n",
      "  d_model (MLP/input): 768 dims\n",
      "  d_head (attention): 64 dims\n",
      "  Total budget: 11200 dims\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import torch\n",
    "import numpy as np\n",
    "import json\n",
    "from transformer_lens import HookedTransformer\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Check device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load GPT2-small\n",
    "print(\"Loading GPT2-small model...\")\n",
    "model = HookedTransformer.from_pretrained(\"gpt2-small\", device=device)\n",
    "\n",
    "# Model configuration\n",
    "print(f\"\\nModel configuration:\")\n",
    "print(f\"  n_layers: {model.cfg.n_layers}\")\n",
    "print(f\"  n_heads: {model.cfg.n_heads}\")\n",
    "print(f\"  d_model: {model.cfg.d_model}\")\n",
    "print(f\"  d_head: {model.cfg.d_head}\")\n",
    "\n",
    "# Budget constraints\n",
    "d_model = model.cfg.d_model\n",
    "d_head = model.cfg.d_head\n",
    "total_budget = 11200\n",
    "\n",
    "print(f\"\\nBudget constraints:\")\n",
    "print(f\"  d_model (MLP/input): {d_model} dims\")\n",
    "print(f\"  d_head (attention): {d_head} dims\")\n",
    "print(f\"  Total budget: {total_budget} dims\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2849d94",
   "metadata": {
    "execution_status": "complete"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 5 sarcastic examples\n",
      "Created 5 non-sarcastic examples\n",
      "\n",
      "Example pairs:\n",
      "\n",
      "Pair 1:\n",
      "  Sarcastic: Oh great, another meeting at 7 AM.\n",
      "  Literal: I'm excited about the meeting at 7 AM tomorrow.\n",
      "\n",
      "Pair 2:\n",
      "  Sarcastic: Wow, I just love getting stuck in traffic.\n",
      "  Literal: I really enjoy my peaceful morning commute.\n",
      "\n",
      "Pair 3:\n",
      "  Sarcastic: Perfect, my computer crashed right before the deadline.\n",
      "  Literal: I'm glad I saved my work before the deadline.\n"
     ]
    }
   ],
   "source": [
    "# Create synthetic sarcastic and literal text examples\n",
    "# Using paired examples as described in the code walk\n",
    "\n",
    "sarcastic_examples = [\n",
    "    \"Oh great, another meeting at 7 AM.\",\n",
    "    \"Wow, I just love getting stuck in traffic.\",\n",
    "    \"Perfect, my computer crashed right before the deadline.\",\n",
    "    \"Fantastic, it's raining on my only day off.\",\n",
    "    \"Amazing, the wifi is down again.\",\n",
    "]\n",
    "\n",
    "non_sarcastic_examples = [\n",
    "    \"I'm excited about the meeting at 7 AM tomorrow.\",\n",
    "    \"I really enjoy my peaceful morning commute.\",\n",
    "    \"I'm glad I saved my work before the deadline.\",\n",
    "    \"I love relaxing at home on my day off.\",\n",
    "    \"The wifi connection is working great today.\",\n",
    "]\n",
    "\n",
    "print(f\"Created {len(sarcastic_examples)} sarcastic examples\")\n",
    "print(f\"Created {len(non_sarcastic_examples)} non-sarcastic examples\")\n",
    "print(f\"\\nExample pairs:\")\n",
    "for i in range(min(3, len(sarcastic_examples))):\n",
    "    print(f\"\\nPair {i+1}:\")\n",
    "    print(f\"  Sarcastic: {sarcastic_examples[i]}\")\n",
    "    print(f\"  Literal: {non_sarcastic_examples[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44500916",
   "metadata": {
    "execution_status": "complete"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model on sarcastic examples...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected activations for 5 sarcastic examples\n",
      "\n",
      "Running model on non-sarcastic examples...\n",
      "Collected activations for 5 literal examples\n",
      "\n",
      "Example cache keys (first example):\n",
      "Total cache keys: 208\n",
      "First 5 keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.ln1.hook_scale', 'blocks.0.ln1.hook_normalized']\n"
     ]
    }
   ],
   "source": [
    "# Function to get model activations for text examples\n",
    "def get_model_logits_and_activations(model, texts):\n",
    "    \"\"\"\n",
    "    Run model on texts and collect all intermediate activations\n",
    "    \n",
    "    Args:\n",
    "        model: HookedTransformer model\n",
    "        texts: List of text strings\n",
    "        \n",
    "    Returns:\n",
    "        List of dicts containing text, tokens, logits, and activation cache\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for text in texts:\n",
    "        # Tokenize with BOS token\n",
    "        tokens = model.to_tokens(text, prepend_bos=True)\n",
    "        \n",
    "        # Run model and cache activations\n",
    "        with torch.no_grad():\n",
    "            logits, cache = model.run_with_cache(tokens)\n",
    "        \n",
    "        results.append({\n",
    "            'text': text,\n",
    "            'tokens': tokens,\n",
    "            'logits': logits,\n",
    "            'cache': cache\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run model on sarcastic examples\n",
    "print(\"Running model on sarcastic examples...\")\n",
    "sarcastic_results = get_model_logits_and_activations(model, sarcastic_examples)\n",
    "print(f\"Collected activations for {len(sarcastic_results)} sarcastic examples\")\n",
    "\n",
    "# Run model on non-sarcastic examples\n",
    "print(\"\\nRunning model on non-sarcastic examples...\")\n",
    "literal_results = get_model_logits_and_activations(model, non_sarcastic_examples)\n",
    "print(f\"Collected activations for {len(literal_results)} literal examples\")\n",
    "\n",
    "print(\"\\nExample cache keys (first example):\")\n",
    "cache_keys = list(sarcastic_results[0]['cache'].keys())\n",
    "print(f\"Total cache keys: {len(cache_keys)}\")\n",
    "print(f\"First 5 keys: {cache_keys[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba8c29f1",
   "metadata": {
    "execution_status": "complete"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test differential activation for blocks.0.hook_mlp_out: 6.9997\n"
     ]
    }
   ],
   "source": [
    "# Function to measure differential activation between two caches\n",
    "def measure_activation_difference_normalized(cache1, cache2, hook_name):\n",
    "    \"\"\"\n",
    "    Measure L2 norm of activation difference between two caches\n",
    "    \n",
    "    Args:\n",
    "        cache1: First activation cache\n",
    "        cache2: Second activation cache\n",
    "        hook_name: Name of the hook point to compare\n",
    "        \n",
    "    Returns:\n",
    "        L2 norm of the difference (scalar)\n",
    "    \"\"\"\n",
    "    if hook_name not in cache1 or hook_name not in cache2:\n",
    "        return 0.0\n",
    "    \n",
    "    # Get activations\n",
    "    act1 = cache1[hook_name]\n",
    "    act2 = cache2[hook_name]\n",
    "    \n",
    "    # Average over sequence dimension (dim=1)\n",
    "    mean1 = act1.mean(dim=1)\n",
    "    mean2 = act2.mean(dim=1)\n",
    "    \n",
    "    # Compute L2 norm of difference\n",
    "    diff = (mean1 - mean2).pow(2).sum().sqrt().item()\n",
    "    \n",
    "    return diff\n",
    "\n",
    "# Test the function with one pair\n",
    "test_hook = 'blocks.0.hook_mlp_out'\n",
    "test_diff = measure_activation_difference_normalized(\n",
    "    sarcastic_results[0]['cache'],\n",
    "    literal_results[0]['cache'],\n",
    "    test_hook\n",
    ")\n",
    "print(f\"Test differential activation for {test_hook}: {test_diff:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01b9c903",
   "metadata": {
    "execution_status": "complete"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing differential activations for all pairs...\n",
      "Computed differential activations for 156 components\n",
      "  MLPs: 12\n",
      "  Attention heads: 144\n"
     ]
    }
   ],
   "source": [
    "# Compute differential activations for all component types across all example pairs\n",
    "# We'll average the differential across all 5 pairs\n",
    "\n",
    "n_layers = model.cfg.n_layers\n",
    "n_heads = model.cfg.n_heads\n",
    "\n",
    "# Dictionary to accumulate differential activations\n",
    "component_diffs = {}\n",
    "\n",
    "print(\"Computing differential activations for all pairs...\")\n",
    "\n",
    "# Process each pair\n",
    "for pair_idx in range(len(sarcastic_examples)):\n",
    "    cache_sarc = sarcastic_results[pair_idx]['cache']\n",
    "    cache_lit = literal_results[pair_idx]['cache']\n",
    "    \n",
    "    # MLP differences for each layer\n",
    "    for layer in range(n_layers):\n",
    "        mlp_key = f'blocks.{layer}.hook_mlp_out'\n",
    "        mlp_diff = measure_activation_difference_normalized(cache_sarc, cache_lit, mlp_key)\n",
    "        \n",
    "        comp_name = f'm{layer}'\n",
    "        if comp_name not in component_diffs:\n",
    "            component_diffs[comp_name] = []\n",
    "        component_diffs[comp_name].append(mlp_diff)\n",
    "    \n",
    "    # Attention head differences for each layer and head\n",
    "    for layer in range(n_layers):\n",
    "        attn_key = f'blocks.{layer}.attn.hook_z'\n",
    "        attn_sarc = cache_sarc[attn_key]\n",
    "        attn_lit = cache_lit[attn_key]\n",
    "        \n",
    "        for head in range(n_heads):\n",
    "            # Extract per-head activations\n",
    "            mean_sarc = attn_sarc[:, :, head, :].mean(dim=1)\n",
    "            mean_lit = attn_lit[:, :, head, :].mean(dim=1)\n",
    "            \n",
    "            # Compute L2 difference\n",
    "            head_diff = (mean_sarc - mean_lit).pow(2).sum().sqrt().item()\n",
    "            \n",
    "            comp_name = f'a{layer}.h{head}'\n",
    "            if comp_name not in component_diffs:\n",
    "                component_diffs[comp_name] = []\n",
    "            component_diffs[comp_name].append(head_diff)\n",
    "\n",
    "# Average across all pairs\n",
    "avg_component_diffs = {}\n",
    "for comp, diffs in component_diffs.items():\n",
    "    avg_component_diffs[comp] = np.mean(diffs)\n",
    "\n",
    "print(f\"Computed differential activations for {len(avg_component_diffs)} components\")\n",
    "print(f\"  MLPs: {len([c for c in avg_component_diffs.keys() if c.startswith('m')])}\")\n",
    "print(f\"  Attention heads: {len([c for c in avg_component_diffs.keys() if c.startswith('a')])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e05b1816",
   "metadata": {
    "execution_status": "complete"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 MLPs by differential activation:\n",
      " 1. m2  :  31.51\n",
      " 2. m11 :  22.32\n",
      " 3. m10 :  17.47\n",
      " 4. m9  :  13.23\n",
      " 5. m8  :  11.51\n",
      " 6. m7  :   9.70\n",
      " 7. m6  :   8.70\n",
      " 8. m1  :   8.07\n",
      " 9. m0  :   7.98\n",
      "10. m5  :   7.59\n",
      "\n",
      "Top 10 Attention Heads by differential activation:\n",
      " 1. a11.h8  :   3.00\n",
      " 2. a11.h0  :   2.59\n",
      " 3. a8.h5   :   1.43\n",
      " 4. a4.h11  :   1.37\n",
      " 5. a6.h11  :   1.36\n",
      " 6. a10.h5  :   1.29\n",
      " 7. a5.h3   :   1.27\n",
      " 8. a11.h3  :   1.24\n",
      " 9. a9.h3   :   1.23\n",
      "10. a8.h10  :   1.22\n",
      "\n",
      "Key Finding Verification:\n",
      "  m2 differential: 31.51\n",
      "  m11 differential: 22.32\n",
      "  Ratio m2/m11: 1.41x\n"
     ]
    }
   ],
   "source": [
    "# Analyze the top components\n",
    "# Separate MLPs and attention heads\n",
    "mlp_components = [(name, diff) for name, diff in avg_component_diffs.items() if name.startswith('m')]\n",
    "attn_components = [(name, diff) for name, diff in avg_component_diffs.items() if name.startswith('a')]\n",
    "\n",
    "# Sort by differential activation\n",
    "mlp_components.sort(key=lambda x: x[1], reverse=True)\n",
    "attn_components.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"Top 10 MLPs by differential activation:\")\n",
    "for i, (name, diff) in enumerate(mlp_components[:10], 1):\n",
    "    print(f\"{i:2d}. {name:4s}: {diff:6.2f}\")\n",
    "\n",
    "print(\"\\nTop 10 Attention Heads by differential activation:\")\n",
    "for i, (name, diff) in enumerate(attn_components[:10], 1):\n",
    "    print(f\"{i:2d}. {name:8s}: {diff:6.2f}\")\n",
    "\n",
    "# Key finding check\n",
    "print(f\"\\nKey Finding Verification:\")\n",
    "print(f\"  m2 differential: {avg_component_diffs['m2']:.2f}\")\n",
    "print(f\"  m11 differential: {avg_component_diffs['m11']:.2f}\")\n",
    "print(f\"  Ratio m2/m11: {avg_component_diffs['m2']/avg_component_diffs['m11']:.2f}x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00b11160",
   "metadata": {
    "execution_status": "complete"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting circuit construction:\n",
      "Initial cost (input): 768 dims\n",
      "\n",
      "Added 10 MLPs (threshold >= 7.0):\n",
      "  m2: 31.51\n",
      "  m11: 22.32\n",
      "  m10: 17.47\n",
      "  m9: 13.23\n",
      "  m8: 11.51\n",
      "  m7: 9.70\n",
      "  m6: 8.70\n",
      "  m1: 8.07\n",
      "  m0: 7.98\n",
      "  m5: 7.59\n",
      "Current cost: 8448 dims\n",
      "\n",
      "Remaining budget: 2752 dims\n",
      "Max attention heads: 43\n",
      "\n",
      "Final circuit composition:\n",
      "  Total components: 54\n",
      "  Input embedding: 1\n",
      "  MLPs: 10\n",
      "  Attention heads: 43\n",
      "  Total write cost: 11200 / 11200 dims\n",
      "  Budget utilization: 100.0%\n"
     ]
    }
   ],
   "source": [
    "# Now construct the circuit based on budget constraints\n",
    "# Strategy: \n",
    "# 1. Always include input embedding (768 dims)\n",
    "# 2. Add high-differential MLPs (threshold ~7.0)\n",
    "# 3. Fill remaining budget with attention heads\n",
    "\n",
    "def calculate_write_cost(components):\n",
    "    \"\"\"Calculate total write cost for a list of components\"\"\"\n",
    "    cost = 0\n",
    "    for comp in components:\n",
    "        if comp == 'input':\n",
    "            cost += d_model  # 768\n",
    "        elif comp.startswith('m'):\n",
    "            cost += d_model  # 768\n",
    "        elif comp.startswith('a'):\n",
    "            cost += d_head  # 64\n",
    "    return cost\n",
    "\n",
    "# Start with input embedding\n",
    "candidate_circuit = ['input']\n",
    "current_cost = d_model\n",
    "\n",
    "print(f\"Starting circuit construction:\")\n",
    "print(f\"Initial cost (input): {current_cost} dims\")\n",
    "\n",
    "# Add high-importance MLPs (threshold = 7.0 based on code walk)\n",
    "mlp_threshold = 7.0\n",
    "selected_mlps = []\n",
    "\n",
    "for comp_name, diff in mlp_components:\n",
    "    if diff >= mlp_threshold:\n",
    "        candidate_circuit.append(comp_name)\n",
    "        selected_mlps.append((comp_name, diff))\n",
    "        current_cost += d_model\n",
    "\n",
    "print(f\"\\nAdded {len(selected_mlps)} MLPs (threshold >= {mlp_threshold}):\")\n",
    "for comp, diff in selected_mlps:\n",
    "    print(f\"  {comp}: {diff:.2f}\")\n",
    "print(f\"Current cost: {current_cost} dims\")\n",
    "\n",
    "# Fill remaining budget with attention heads\n",
    "remaining_budget = total_budget - current_cost\n",
    "max_heads = remaining_budget // d_head\n",
    "\n",
    "print(f\"\\nRemaining budget: {remaining_budget} dims\")\n",
    "print(f\"Max attention heads: {max_heads}\")\n",
    "\n",
    "selected_heads = attn_components[:max_heads]\n",
    "for comp_name, diff in selected_heads:\n",
    "    candidate_circuit.append(comp_name)\n",
    "    current_cost += d_head\n",
    "\n",
    "final_cost = calculate_write_cost(candidate_circuit)\n",
    "\n",
    "print(f\"\\nFinal circuit composition:\")\n",
    "print(f\"  Total components: {len(candidate_circuit)}\")\n",
    "print(f\"  Input embedding: 1\")\n",
    "print(f\"  MLPs: {len(selected_mlps)}\")\n",
    "print(f\"  Attention heads: {len(selected_heads)}\")\n",
    "print(f\"  Total write cost: {final_cost} / {total_budget} dims\")\n",
    "print(f\"  Budget utilization: {100 * final_cost / total_budget:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fdbbefc0",
   "metadata": {
    "execution_status": "complete"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output directory: /home/smallyan/critic_model_mechinterp/runs/circuits_claude_2025-11-10_20-48-00/evaluation/replication\n",
      "Timestamp: 20251113_232235\n",
      "\n",
      "Saved replicated circuit to: /home/smallyan/critic_model_mechinterp/runs/circuits_claude_2025-11-10_20-48-00/evaluation/replication/replicated_circuit.json\n",
      "\n",
      "First 15 nodes in circuit:\n",
      "   1. input\n",
      "   2. m2\n",
      "   3. m11\n",
      "   4. m10\n",
      "   5. m9\n",
      "   6. m8\n",
      "   7. m7\n",
      "   8. m6\n",
      "   9. m1\n",
      "  10. m0\n",
      "  11. m5\n",
      "  12. a11.h8\n",
      "  13. a11.h0\n",
      "  14. a8.h5\n",
      "  15. a4.h11\n"
     ]
    }
   ],
   "source": [
    "# Create output directory for replication results\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Create evaluation/replication directory with timestamp\n",
    "output_dir = os.path.join(REPO_ROOT, 'evaluation', 'replication')\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "print(f\"Output directory: {output_dir}\")\n",
    "print(f\"Timestamp: {timestamp}\")\n",
    "\n",
    "# Prepare circuit output in required JSON format\n",
    "circuit_output = {\n",
    "    \"nodes\": candidate_circuit,\n",
    "    \"metadata\": {\n",
    "        \"total_components\": len(candidate_circuit),\n",
    "        \"write_budget_used\": final_cost,\n",
    "        \"write_budget_max\": total_budget,\n",
    "        \"budget_utilization\": f\"{100 * final_cost / total_budget:.1f}%\",\n",
    "        \"num_mlps\": len(selected_mlps),\n",
    "        \"num_attention_heads\": len(selected_heads),\n",
    "        \"model\": \"gpt2-small\",\n",
    "        \"task\": \"sarcasm_detection\",\n",
    "        \"version\": \"replication\",\n",
    "        \"method\": \"differential_activation_analysis\",\n",
    "        \"replication_timestamp\": timestamp\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save replicated circuit\n",
    "circuit_path = os.path.join(output_dir, 'replicated_circuit.json')\n",
    "with open(circuit_path, 'w') as f:\n",
    "    json.dump(circuit_output, f, indent=2)\n",
    "\n",
    "print(f\"\\nSaved replicated circuit to: {circuit_path}\")\n",
    "\n",
    "# Display first few nodes to verify\n",
    "print(f\"\\nFirst 15 nodes in circuit:\")\n",
    "for i, node in enumerate(candidate_circuit[:15], 1):\n",
    "    print(f\"  {i:2d}. {node}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3ab4b51",
   "metadata": {
    "execution_status": "complete"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIRCUIT COMPARISON\n",
      "============================================================\n",
      "\n",
      "Metadata Comparison:\n",
      "Metric                             Original   Replicated\n",
      "------------------------------------------------------------\n",
      "Total components                         54           54\n",
      "MLPs                                     10           10\n",
      "Attention heads                          43           43\n",
      "Write budget used                     11200        11200\n",
      "\n",
      "Node Comparison:\n",
      "  Matching nodes: 51 / 54 (94.4%)\n",
      "  Only in original: 3\n",
      "  Only in replicated: 3\n",
      "\n",
      "MLP Component Comparison:\n",
      "  Original MLPs: ['m2', 'm11', 'm10', 'm9', 'm8', 'm7', 'm6', 'm1', 'm5', 'm0']\n",
      "  Replicated MLPs: ['m2', 'm11', 'm10', 'm9', 'm8', 'm7', 'm6', 'm1', 'm0', 'm5']\n",
      "  MLPs match: False\n",
      "\n",
      "Top 5 Attention Heads:\n",
      "  Original: ['a11.h8', 'a11.h0', 'a4.h11', 'a9.h3', 'a6.h11']\n",
      "  Replicated: ['a11.h8', 'a11.h0', 'a8.h5', 'a4.h11', 'a6.h11']\n"
     ]
    }
   ],
   "source": [
    "# Compare replicated circuit with original circuit\n",
    "original_circuit_path = os.path.join(REPO_ROOT, 'results', 'real_circuits_1.json')\n",
    "\n",
    "with open(original_circuit_path, 'r') as f:\n",
    "    original_circuit = json.load(f)\n",
    "\n",
    "print(\"CIRCUIT COMPARISON\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Compare metadata\n",
    "print(\"\\nMetadata Comparison:\")\n",
    "print(f\"{'Metric':<30} {'Original':>12} {'Replicated':>12}\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'Total components':<30} {original_circuit['metadata']['total_components']:>12} {circuit_output['metadata']['total_components']:>12}\")\n",
    "print(f\"{'MLPs':<30} {original_circuit['metadata']['num_mlps']:>12} {circuit_output['metadata']['num_mlps']:>12}\")\n",
    "print(f\"{'Attention heads':<30} {original_circuit['metadata']['num_attention_heads']:>12} {circuit_output['metadata']['num_attention_heads']:>12}\")\n",
    "print(f\"{'Write budget used':<30} {original_circuit['metadata']['write_budget_used']:>12} {circuit_output['metadata']['write_budget_used']:>12}\")\n",
    "\n",
    "# Compare nodes\n",
    "original_nodes = set(original_circuit['nodes'])\n",
    "replicated_nodes = set(circuit_output['nodes'])\n",
    "\n",
    "matching_nodes = original_nodes & replicated_nodes\n",
    "only_original = original_nodes - replicated_nodes\n",
    "only_replicated = replicated_nodes - original_nodes\n",
    "\n",
    "print(f\"\\nNode Comparison:\")\n",
    "print(f\"  Matching nodes: {len(matching_nodes)} / {len(original_nodes)} ({100*len(matching_nodes)/len(original_nodes):.1f}%)\")\n",
    "print(f\"  Only in original: {len(only_original)}\")\n",
    "print(f\"  Only in replicated: {len(only_replicated)}\")\n",
    "\n",
    "# Check if MLP ordering matches\n",
    "original_mlps = [n for n in original_circuit['nodes'] if n.startswith('m')]\n",
    "replicated_mlps = [n for n in circuit_output['nodes'] if n.startswith('m')]\n",
    "\n",
    "print(f\"\\nMLP Component Comparison:\")\n",
    "print(f\"  Original MLPs: {original_mlps}\")\n",
    "print(f\"  Replicated MLPs: {replicated_mlps}\")\n",
    "print(f\"  MLPs match: {original_mlps == replicated_mlps}\")\n",
    "\n",
    "# Show top attention heads\n",
    "original_attn_top5 = [n for n in original_circuit['nodes'] if n.startswith('a')][:5]\n",
    "replicated_attn_top5 = [n for n in circuit_output['nodes'] if n.startswith('a')][:5]\n",
    "\n",
    "print(f\"\\nTop 5 Attention Heads:\")\n",
    "print(f\"  Original: {original_attn_top5}\")\n",
    "print(f\"  Replicated: {replicated_attn_top5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af88ad87",
   "metadata": {
    "execution_status": "complete"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed MLP Comparison:\n",
      "Component  Original Pos    Replicated Pos  Match     \n",
      "------------------------------------------------------------\n",
      "m2         0               0               ✓         \n",
      "m11        1               1               ✓         \n",
      "m10        2               2               ✓         \n",
      "m9         3               3               ✓         \n",
      "m8         4               4               ✓         \n",
      "m7         5               5               ✓         \n",
      "m6         6               6               ✓         \n",
      "m1         7               7               ✓         \n",
      "m0         9               8               ✓         \n",
      "m5         8               9               ✓         \n",
      "\n",
      "All MLPs present in both: True\n",
      "\n",
      "============================================================\n",
      "Attention Head Differences:\n",
      "============================================================\n",
      "\n",
      "Only in original (3):\n",
      "  a3.h6\n",
      "  a4.h3\n",
      "  a8.h2\n",
      "\n",
      "Only in replicated (3):\n",
      "  a11.h10\n",
      "  a2.h9\n",
      "  a3.h7\n",
      "\n",
      "Differential activation scores for mismatched heads:\n",
      "  a11.h10: 0.8578 (rank 37)\n",
      "  a2.h9: 0.8701 (rank 36)\n",
      "  a3.h6: 0.8009 (rank 46)\n",
      "  a3.h7: 0.8319 (rank 42)\n",
      "  a4.h3: 0.7940 (rank 48)\n",
      "  a8.h2: 0.7937 (rank 49)\n"
     ]
    }
   ],
   "source": [
    "# Investigate the MLP ordering difference\n",
    "# The same MLPs were selected, just in slightly different order\n",
    "\n",
    "print(\"Detailed MLP Comparison:\")\n",
    "print(f\"{'Component':<10} {'Original Pos':<15} {'Replicated Pos':<15} {'Match':<10}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for mlp in replicated_mlps:\n",
    "    orig_pos = original_mlps.index(mlp) if mlp in original_mlps else -1\n",
    "    repl_pos = replicated_mlps.index(mlp)\n",
    "    match = \"✓\" if mlp in original_mlps else \"✗\"\n",
    "    print(f\"{mlp:<10} {orig_pos:<15} {repl_pos:<15} {match:<10}\")\n",
    "\n",
    "print(f\"\\nAll MLPs present in both: {set(original_mlps) == set(replicated_mlps)}\")\n",
    "\n",
    "# Investigate attention head differences\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Attention Head Differences:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if only_original:\n",
    "    print(f\"\\nOnly in original ({len(only_original)}):\")\n",
    "    for node in sorted(only_original):\n",
    "        print(f\"  {node}\")\n",
    "\n",
    "if only_replicated:\n",
    "    print(f\"\\nOnly in replicated ({len(only_replicated)}):\")\n",
    "    for node in sorted(only_replicated):\n",
    "        print(f\"  {node}\")\n",
    "\n",
    "# Get rankings for the mismatched heads\n",
    "print(\"\\nDifferential activation scores for mismatched heads:\")\n",
    "mismatched_heads = only_original | only_replicated\n",
    "for head in sorted(mismatched_heads):\n",
    "    if head in avg_component_diffs:\n",
    "        score = avg_component_diffs[head]\n",
    "        # Find rank\n",
    "        rank = [i for i, (n, d) in enumerate(attn_components, 1) if n == head][0]\n",
    "        print(f\"  {head}: {score:.4f} (rank {rank})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cab2c4f",
   "metadata": {},
   "source": [
    "## Replication Results Summary\n",
    "\n",
    "### Circuit Fidelity\n",
    "- **Total components**: 54/54 (100% match)\n",
    "- **Matching nodes**: 51/54 (94.4%)\n",
    "- **All MLPs match**: Yes (same 10 MLPs, minor ordering difference for m0 and m5)\n",
    "- **Top attention heads match**: 4/5 of top 5 match\n",
    "\n",
    "### Key Findings Replicated\n",
    "1. **m2 dominance**: 31.51 (vs. expected ~32.47) - 97% match\n",
    "2. **m11 second strongest**: 22.32 (vs. expected 22.30) - 99.9% match\n",
    "3. **Layer 11 attention heads strongest**: a11.h8 (3.00) and a11.h0 (2.59) match perfectly\n",
    "\n",
    "### Minor Differences\n",
    "- **3 attention heads differ** (ranks 36-49) due to:\n",
    "  - Very close differential scores (0.79-0.87)\n",
    "  - Statistical variation across runs\n",
    "  - Likely within margin of error for such small differences\n",
    "\n",
    "### Conclusion\n",
    "Replication successful with 94.4% node overlap and near-perfect match on key findings (m2, m11, Layer 11 heads)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa159b90",
   "metadata": {
    "execution_status": "pending"
   },
   "outputs": [],
   "source": [
    "# Save the current notebook to the replication directory\n",
    "import shutil\n",
    "\n",
    "# Get current notebook path\n",
    "current_notebook = \"/home/smallyan/critic_model_mechinterp/notebooks/2025-11-13-23-18_CircuitAnalysis.ipynb\"\n",
    "target_notebook = os.path.join(output_dir, \"replication.ipynb\")\n",
    "\n",
    "# Copy the notebook\n",
    "shutil.copy2(current_notebook, target_notebook)\n",
    "print(f\"Saved replication notebook to: {target_notebook}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scribe: 2025-11-13-23-18_CircuitAnalysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
