# Large Circuit Tracing Experiment — IOI Circuit

## PLAN FILE — DO NOT MODIFY

### ROLE

You are a **senior mechanistic interpretability researcher**.

### MODEL AND DATA

* Use model: **gpt2-small** loaded via **HookedTransformer**.
* Use dataset: **mib-bench/ioi**.
* Ignore files under `runs/`.

### GOAL

Identify a **precise circuit**—a subset of attention heads and MLPs—that reproduces the model’s **Indirect Object Identification (IOI)** behavior as faithfully as possible while obeying strict **residual write-budget constraints**.

---

### TASK DESCRIPTION

A sentence in the IOI dataset has an **initial dependent clause** and a **main clause**:
Example: *“When Mary and John went to the store, John gave a bottle of milk to Mary.”*

* The dependent clause introduces the **Indirect Object (IO)** “Mary” and the **Subject (S)** “John”.
* The main clause refers to the subject again, and the model must predict that the **final token** is the **IO**.
* We use `S1` and `S2` to denote the first and second subject mentions.
* The IOI task evaluates whether the model correctly predicts the final IO token.

---

### HYPOTHESIS (Circuit Proposal)

The IOI circuit is hypothesized to include three main head types:

1. **Duplicate Token Heads**

   * Active at `S2`.
   * Attend to `S1`.
   * Signal duplicate detection by writing the position of the duplicated token.

2. **S-Inhibition Heads**

   * Active at `END`.
   * Attend to `S2`.
   * Write into Name-Mover queries to **inhibit attention to S1 and S2**.

3. **Name-Mover Heads**

   * Active at `END`.
   * Attend to prior names.
   * Copy the IO token name into the residual stream due to inhibition of subject tokens.

These collectively yield correct IOI predictions by suppressing subject interference.

---

### SRC_NODES

```
[
  'input',
  'a0.h0','a0.h1',...,'a0.h11','m0',
  'a1.h0',...,'a1.h11','m1',
  'a2.h0',...,'a2.h11','m2',
  'a3.h0',...,'a3.h11','m3',
  'a4.h0',...,'a4.h11','m4',
  'a5.h0',...,'a5.h11','m5',
  'a6.h0',...,'a6.h11','m6',
  'a7.h0',...,'a7.h11','m7',
  'a8.h0',...,'a8.h11','m8',
  'a9.h0',...,'a9.h11','m9',
  'a10.h0',...,'a10.h11','m10',
  'a11.h0',...,'a11.h11','m11'
]
```

### CONSTRAINTS

* You should always generate a plan before implementation.
* Each attention head writes `d_model / n_heads` dimensions.
* Each MLP writes `d_model` dimensions.
* **Total writes ≤ 11,200**.
* Only use nodes from `src_nodes`.
* Naming must follow `a{layer}.h{head}`, `m{layer}`, or `input`.

---

## EXPERIMENT STEPS

### 1. INITIALIZATION

* Open a new notebook.
* Load **HookedTransformer (gpt2-small)**.
* Load the **mib-bench/ioi** dataset (factual and counterfactual prompts).
* Load node list (`src_nodes`).

---

### 2. PROBE INTERNAL NODES

Use **HookedTransformer** hooks to analyze internal activations from `src_nodes`.

**a. Add Hooks**

* Hook outputs of attention heads and MLPs at the residual stream write points.
* Record activations; support ablation (zero-out) and patching (replace with counterfactuals).

**b. Run Counterfactual Patching**

* For each factual example, patch activations from the matching counterfactual example.
* Measure **logit difference** or **rank** for the correct IO token.
* Aggregate across examples to find nodes most critical to IOI accuracy.

---

### 3. TRACE AND LOCALIZE THE MINIMAL CIRCUIT

Identify the minimal node subset that:

1. Fully restores IOI behavior when their activations are preserved or patched from clean examples.
2. Fails when ablated, confirming necessity.
3. Meets the **11,200-dimension write budget**.

Print model behavior **before and after intervention** for comparison.

---

### 4. CIRCUIT IDENTIFICATION STRATEGY

You may use any combination of:

* Node-wise patching and ablation.
* Gradient approximations for faster screening.
* Greedy subset search under the write-budget.
  Goal: isolate **necessary and sufficient** nodes for IOI behavior.

---

### 5. RESULTS AND OUTPUTS

Once a valid circuit is found:

Save node list to `real_circuits_1.json`:

```json
{
  "nodes": ["input", "a3.h4", "m4", ...]
}
```

Double-check:

* All nodes appear in `src_nodes`.
* Total writes ≤ 11,200.
* Naming is consistent.

---

## FILES TO PRODUCE

**Logs (Markdown):**

* `logs/plan.md`
* `logs/documentation.md`
* `logs/code_walk.md`

**Notebooks:**

* `notebooks/plan_Md.ipynb`
* `notebooks/documentation_Md.ipynb`
* `notebooks/code_walk_Md.ipynb`

---

## DOCUMENTATION REQUIREMENTS

`logs/documentation.md` must include:

1. **Goal** — Hypothesis and components tested.
2. **Data** — Example IOI sentence pair (factual vs. counterfactual).
3. **Experiments** — Methods, tools, number of samples, and metrics.
4. **Results** — Logit differences, rank accuracy, before/after intervention plots.
5. **Analysis** — Which heads/MLPs are necessary or sufficient.
6. **Next Steps** — Scaling to other syntax structures or larger models.

---

## OUTPUT SUMMARY

* Final circuit JSON (`real_circuits_1.json`).
* Metric tables before/after interventions.
* Documentation and walkthrough notebooks under required paths.
* Optional plots and activation visualizations.

